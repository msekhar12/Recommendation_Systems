{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Jokes Recommender system\n",
    "### Sekhar Mekala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Requirements\n",
    "\n",
    "The main goal of this project is to analyze a massive data set with at least 1 million ratings, preferably using a distributed processing system such as Hadoop. In this project, I will be analyzing a 1.7 million continuous ratings (-10.00 to +10.00) of 150 jokes rated by 59132 users. Please visit http://eigentaste.berkeley.edu/dataset/ for more information about the data set. The main deliverables of this project are:\n",
    "* Develop a collaborative filtering algorithm in a distributed processing environment using PySpark. The algorithm is implemented on 1.7 million ratings data set, in Hadoop environment. We cannot implement the proposed algorithm on a laptop or a stand-alone machine, since the logic of the algorithm requires a self join with the ratings data set, along with complex processing logic. We will be using Spark 1.6.1 version as our distributed processing environment. \n",
    "\n",
    "* Develop another recommender system using SGD (Stochastic Gradient Descent) algorithm on a stand alone machine, and evaluate the algorithm's performance on the 1.7 million ratings data set. \n",
    "\n",
    "**NOTE** \n",
    "\n",
    "* Although we will be building recommender systems using the jokes dataset, the same python code can be used to build similar recommender systems using other data sets also. The only requirement for the implementation of SGD based recommender system is the format of the input data frame. The input data frame must have the following columns:\n",
    "\n",
    "*user_id,item_id,rating*\n",
    "\n",
    "The user_id and item_id are integers, and rating can be any real number. There must not be any unavailable or NA values in the input data frame. \n",
    "\n",
    "* Please download the jester_ratings.dat and jester_items.dat from http://eigentaste.berkeley.edu/dataset/ (Dataset 2), to follow along the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender system - 1\n",
    "\n",
    "### Collaborative filtering algorithm\n",
    "\n",
    "We will develop a collaborative filtering algorithm based on the cosine similarity between the pairs of jokes that are rated by at least one common user. \n",
    "\n",
    "We have 2 data sets: *jester_ratings.dat* and *jester_items.dat*. The *jester_ratings.dat* data set has the following format (tab separated):\n",
    "\n",
    "_user-id_,  _joke-id_,  _rating_\n",
    "\n",
    "The *jester_items.dat* has the _joke-id_ and the actual joke (HTML text), separated by a \":\"\n",
    "\n",
    "We will be performing the following steps to build a collaborative recommender system using PySpark on Spark environment:\n",
    "\n",
    "1. Normalize the ratings of the items, based on the following logic. Normalization helps us to remove the user and item biases:\n",
    "\n",
    "   a. Get the mean rating of each joke. \n",
    "\n",
    "   b. Get the mean rating of each user.\n",
    "   \n",
    "   c. Subtract the mean ratings of each joke (say _j_) and the mean rating of user (say _u_) from the actual rating of the joke.\n",
    "\n",
    "2. Using the normalized ratings, compute the cosine similarity between all the pairs of jokes, which are rated by _same users_. The cosine similarity will help us to identify the potential jokes that a user could like based on the jokes which were already liked by the user. To exploit the spark's distributed processing, we will use the following logic to compute the cosine similarity between the pairs of jokes:\n",
    "\n",
    "   a. Read the contents of jester_ratings.dat into an RDD (Resilient Distributed Dataset), with _user-id_ as the key and _(joke-id, rating)_ as values. Let this RDD be _ratings-rdd_. Pratition the RDD for parallel processing.\n",
    "   \n",
    "   b. Get the self join of this RDD (_ratings-rdd_), and filter the rows to eliminate duplicate jokes (details of the filtering process is explained using an example in *Appendix-B*). Let us call this RDD as _joke-pairs-rdd_. The key of this RDD will be _(joke-id-1, joke-id-2)_ and the value will be _(joke-id-1-rating, joke-id-2-rating)_.\n",
    "   \n",
    "   c. Group by the _joke-pairs-rdd_ by its keys, and perform the cosine similarity of the values. Let the resulting RDD be called as _jokes-similarity-rdd_. This RDD will have the cosine similarity between the pairs of jokes. The number of users who rated the jokes pairs is also recorded in the RDD\n",
    "   \n",
    "   d. Write the _jokes-similarity-rdd_ to HDFS\n",
    "   \n",
    "   e. Combine all the components of _jokes-similarity-rdd_ into a single file, and download that file to a local linux directory. The file is finally downloaded to your desired local machine/server location, where the recommendation algorithm will run.\n",
    "\n",
    "3. To make recommendations to a user:\n",
    "\n",
    "   a. Read the cosine similarity file into a Pandas data frame. Call this data frame as _jokes-sim-df_\n",
    "   \n",
    "   b. Get 5 joke-ids which are rated high by the user\n",
    "   \n",
    "   c. For each of the 5 joke-ids, get all the jokes associated with these 5 joke-ids from _jokes-sim-df_. These associated 5 joke-ids must be rated by at least 1000 users. Rank the jokes in the descending order of _similarity measure_\n",
    "   \n",
    "   d. Pick the top 5 jokes from the ordered items, and present them to the user. These items must not be already rated by the user. \n",
    "\n",
    "See *Appendix-B* for the complete implementation of this process using PySpark. *Appendix-A* contains a detailed walk through of the above logic on a small data set. Using the process explained in *Appendix-B*, we can obtain a file (jokes_sim.txt) that contains the cosine similarity between each pairs of jokes, along with the number of users who rated both the jokes in the pair. We will use this file to build our collaborative recommender system. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required python packages\n",
    "The following block imports all the required python packages for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import time\n",
    "import warnings\n",
    "import itertools    \n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.sparse.linalg import svds\n",
    "from bs4 import BeautifulSoup #To extract text from HTML\n",
    "import io #To process buffer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the similarity measures data\n",
    "\n",
    "The following code will read the jokes_sim.txt file (produced by the PySpark program in *Appendix-B*), cleans the data and creates a data frame with the following format given below. If you do not have Spark environment, you may download the jokes_sim.txt from the Github location (https://goo.gl/mEE6G6) of this project and build the recommender directly using the cosine similarity scores in the jokes_sim.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the records from the joke similarity scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-1</th>\n",
       "      <th>Joke-2</th>\n",
       "      <th>Sim-score</th>\n",
       "      <th>Total-votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>124</td>\n",
       "      <td>0.122780</td>\n",
       "      <td>3604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>0.223450</td>\n",
       "      <td>4164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>144</td>\n",
       "      <td>0.129519</td>\n",
       "      <td>5521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>132</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>6989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>0.104506</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Joke-1  Joke-2  Sim-score  Total-votes\n",
       "0      34     124   0.122780         3604\n",
       "1      30      60   0.223450         4164\n",
       "2      94     144   0.129519         5521\n",
       "3      42     132   0.255833         6989\n",
       "4      20      54   0.104506          265"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "with open('jokes_sim.txt', 'r') as file :\n",
    "    filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = filedata.replace('(', '')\n",
    "filedata = filedata.replace(')', '')\n",
    "jokes_sim_df=pd.read_csv(io.BytesIO(filedata), header=None )\n",
    "jokes_sim_df.columns = [\"Joke-1\",\"Joke-2\",\"Sim-score\",\"Total-votes\"]\n",
    "print \"Some of the records from the joke similarity scores:\"\n",
    "display(jokes_sim_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in the similarity scores data frame should be interpreted as follows:\n",
    "1. The column _Joke-1_ represents a joke ID\n",
    "2. The column _Joke-2_ represents another joke ID. Both _Joke-1_ and _Joke-2_ were rated by at least one user in common\n",
    "3. The column _Sim-score_ represents the cosine similarity between _Joke-1_ and _Joke-2_. The range of this similarity is [-1, 1]. Greater the similarity score, more similar are the jokes.\n",
    "4. The column _Total-votes_ represents the number of people who voted both the jokes present in _Joke-1_ and _Joke-2_ columns in common\n",
    "5. For a joke ID _j_ in _Joke-1_ column, the related joke IDs in _Joke-2_ column are greater than joke ID _j_. For example, for joke ID 42 (Joke-1 = 42), the Joke-2 column must be greater than 42. See the below display of some of the records where Joke-1 = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying some of the records, where Joke-ID = 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-1</th>\n",
       "      <th>Joke-2</th>\n",
       "      <th>Sim-score</th>\n",
       "      <th>Total-votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>-0.074450</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>0.089601</td>\n",
       "      <td>4084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>0.185390</td>\n",
       "      <td>5274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>42</td>\n",
       "      <td>46</td>\n",
       "      <td>0.252586</td>\n",
       "      <td>6110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "      <td>0.166835</td>\n",
       "      <td>6967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8172</th>\n",
       "      <td>42</td>\n",
       "      <td>48</td>\n",
       "      <td>0.178894</td>\n",
       "      <td>6662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8901</th>\n",
       "      <td>42</td>\n",
       "      <td>49</td>\n",
       "      <td>0.195952</td>\n",
       "      <td>6973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8024</th>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>0.205549</td>\n",
       "      <td>8006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7857</th>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>0.262250</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>42</td>\n",
       "      <td>52</td>\n",
       "      <td>0.163794</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7732</th>\n",
       "      <td>42</td>\n",
       "      <td>53</td>\n",
       "      <td>0.237151</td>\n",
       "      <td>7839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6857</th>\n",
       "      <td>42</td>\n",
       "      <td>54</td>\n",
       "      <td>0.182889</td>\n",
       "      <td>7062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6694</th>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "      <td>0.113013</td>\n",
       "      <td>4609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>42</td>\n",
       "      <td>56</td>\n",
       "      <td>0.254815</td>\n",
       "      <td>6701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>0.106067</td>\n",
       "      <td>4048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Joke-1  Joke-2  Sim-score  Total-votes\n",
       "5272      42      43  -0.074450          127\n",
       "4449      42      44   0.089601         4084\n",
       "5112      42      45   0.185390         5274\n",
       "4284      42      46   0.252586         6110\n",
       "4108      42      47   0.166835         6967\n",
       "8172      42      48   0.178894         6662\n",
       "8901      42      49   0.195952         6973\n",
       "8024      42      50   0.205549         8006\n",
       "7857      42      51   0.262250          129\n",
       "7000      42      52   0.163794          136\n",
       "7732      42      53   0.237151         7839\n",
       "6857      42      54   0.182889         7062\n",
       "6694      42      55   0.113013         4609\n",
       "896       42      56   0.254815         6701\n",
       "1594      42      57   0.106067         4048"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print \"Displaying some of the records, where Joke-ID = 42\"\n",
    "display(jokes_sim_df[jokes_sim_df[\"Joke-1\"] == 42].sort([\"Joke-2\"]).head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the jokes text\n",
    "The following code will process the *jester_items.dat*, extracts the joke IDs and the jokes text, and outputs a data frame called *items_df*. This data frame will be referenced to extract the Jokes text, based on a joke ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the text of joke ID 144, to make sure that we parsed the Jokes text correctly\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>144</td>\n",
       "      <td>A man is driving in the country one evening when his car stalls and won't start. He goes up to a nearby farm house for help, and because it is suppertime he is asked to stay for supper. When he sits down at the table he notices that a pig is sitting at the table with them for supper and that the pig has a wooden leg. As they are eating and chatting, he eventually asks the farmer why the pig is there and why it has a wooden leg. \"Oh,\" says the farmer, \"that is a very special pig. Last month my wife and daughter were in the barn when it caught fire. The pig saw this, ran to the barn, tipped over a pail of water, crawled over the wet floor to reach them and pulled them out of the barn safely. A special pig like that, you just don't eat it all at once!\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke-id  \\\n",
       "143      144   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Text  \n",
       "143   A man is driving in the country one evening when his car stalls and won't start. He goes up to a nearby farm house for help, and because it is suppertime he is asked to stay for supper. When he sits down at the table he notices that a pig is sitting at the table with them for supper and that the pig has a wooden leg. As they are eating and chatting, he eventually asks the farmer why the pig is there and why it has a wooden leg. \"Oh,\" says the farmer, \"that is a very special pig. Last month my wife and daughter were in the barn when it caught fire. The pig saw this, ran to the barn, tipped over a pail of water, crawled over the wet floor to reach them and pulled them out of the barn safely. A special pig like that, you just don't eat it all at once!\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Use bs4 to extract the text from HTML documents\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"jester_items.dat\", 'r') as file :\n",
    "    filedata = file.read()\n",
    "\n",
    "soup = BeautifulSoup(filedata)\n",
    "text = soup.get_text() \n",
    "\n",
    "#Output the text to a file.\n",
    "with open(\"output.txt\", \"wb\") as outfile:\n",
    "    outfile.write(text)\n",
    "\n",
    "#Define a list \"l\"    \n",
    "l = list()\n",
    "for line in open(r'output.txt'):\n",
    "    #if line != \" \": \n",
    "        l.append(line.strip(\":\\n\"))\n",
    "#print l\n",
    "\n",
    "##Weed out empty elements from the list\n",
    "l = [i for i in l if i != ''] \n",
    "\n",
    "## Define a function that checks if a string has a number\n",
    "def RepresentsInt(s):\n",
    "    try: \n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "##List object to accumulate the joke IDs\n",
    "id = list()\n",
    "\n",
    "##List object to accumulate the jokes text\n",
    "text = list()\n",
    "\n",
    "##Temporary string object to append jokes text, since\n",
    "##A joke can be split into more than one elements in \"l\"\n",
    "s = str()\n",
    "for i in l:\n",
    "    if RepresentsInt(i):\n",
    "            if len(s) > 0: ##This will ignore the initial condition\n",
    "                text.append(s)\n",
    "                s = str()\n",
    "            id.append(int(i))\n",
    "    else:\n",
    "        s = s + \" \" + str(i)\n",
    "text.append(s)\n",
    "\n",
    "pd.options.display.max_colwidth = 10000\n",
    "items_df = pd.DataFrame(zip(id,text),columns=[\"Joke-id\",\"Text\"])\n",
    "\n",
    "print \"Displaying the text of joke ID 144, to make sure that we parsed the Jokes text correctly\"\n",
    "display(items_df[items_df[\"Joke-id\"] == 144])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above display confirms that the text has been cleaned properly, since there are no embedded HTML Tags or any unreadable characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the similarity scores\n",
    "\n",
    "**Top 5 similar jokes**\n",
    "\n",
    "Let us get the top 5 most similar jokes. These joke pairs were rated by at least 1000 users in common. We will extract the jokes text from item_df to display the jokes text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 jokes having highest similarity scores and rated by atleast 1000 users\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-1</th>\n",
       "      <th>Joke-2</th>\n",
       "      <th>Sim-score</th>\n",
       "      <th>Total-votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>123</td>\n",
       "      <td>140</td>\n",
       "      <td>0.675881</td>\n",
       "      <td>4224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "      <td>0.608029</td>\n",
       "      <td>6061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7150</th>\n",
       "      <td>138</td>\n",
       "      <td>139</td>\n",
       "      <td>0.460189</td>\n",
       "      <td>9707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510</th>\n",
       "      <td>60</td>\n",
       "      <td>101</td>\n",
       "      <td>0.452867</td>\n",
       "      <td>4078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>58</td>\n",
       "      <td>74</td>\n",
       "      <td>0.452844</td>\n",
       "      <td>3754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Joke-1  Joke-2  Sim-score  Total-votes\n",
       "2184     123     140   0.675881         4224\n",
       "3039      86      94   0.608029         6061\n",
       "7150     138     139   0.460189         9707\n",
       "9510      60     101   0.452867         4078\n",
       "1452      58      74   0.452844         3754"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke IDs:[123, 140]. Similarity score: 0.675880827987, Total votes: 4224\n",
      "Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>123</td>\n",
       "      <td>When most people claim to be \"killing time\", it's only an expression. When Chuck Norris kills time, the minutes actually cease to exist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>140</td>\n",
       "      <td>Chuck Norris' calendar goes straight from March 31st to April 2nd; no one fools Chuck Norris.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke-id  \\\n",
       "122      123   \n",
       "139      140   \n",
       "\n",
       "                                                                                                                                          Text  \n",
       "122   When most people claim to be \"killing time\", it's only an expression. When Chuck Norris kills time, the minutes actually cease to exist.  \n",
       "139                                              Chuck Norris' calendar goes straight from March 31st to April 2nd; no one fools Chuck Norris.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke IDs:[86, 94]. Similarity score: 0.60802866823, Total votes: 6061\n",
      "Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>A neutron walks into a bar and orders a drink. \"How much do I owe you?\" the neutron asks. The bartender replies, \"For you, no charge.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>Two atoms are walking down the street when one atom says to the other, \"Oh, my! I've lost an electron!\" The second atom says, \"Are you sure?\" The first replies, \"I'm positive!\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Joke-id  \\\n",
       "85       86   \n",
       "93       94   \n",
       "\n",
       "                                                                                                                                                                                 Text  \n",
       "85                                             A neutron walks into a bar and orders a drink. \"How much do I owe you?\" the neutron asks. The bartender replies, \"For you, no charge.\"  \n",
       "93   Two atoms are walking down the street when one atom says to the other, \"Oh, my! I've lost an electron!\" The second atom says, \"Are you sure?\" The first replies, \"I'm positive!\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke IDs:[138, 139]. Similarity score: 0.460188696353, Total votes: 9707\n",
      "Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138</td>\n",
       "      <td>WASHINGTON (Reuters) - A tragic fire on Monday destroyed the personal library of President George W. Bush. Both of his books have been lost. Presidential spokesman Ari Fleischer said the president was devastated, as he had not finished coloring the second one.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>139</td>\n",
       "      <td>In a Veteran's Day speech, President Bush vowed, \"We will finish the mission. Period.\" Afterwards, he was advised that he doesn't have to read the punctuation marks.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke-id  \\\n",
       "137      138   \n",
       "138      139   \n",
       "\n",
       "                                                                                                                                                                                                                                                                      Text  \n",
       "137   WASHINGTON (Reuters) - A tragic fire on Monday destroyed the personal library of President George W. Bush. Both of his books have been lost. Presidential spokesman Ari Fleischer said the president was devastated, as he had not finished coloring the second one.  \n",
       "138                                                                                                  In a Veteran's Day speech, President Bush vowed, \"We will finish the mission. Period.\" Afterwards, he was advised that he doesn't have to read the punctuation marks.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke IDs:[60, 101]. Similarity score: 0.452866716935, Total votes: 4078\n",
      "Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>What did the Buddhist say to the hot dog vendor? Make me one with everything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>Did you hear about the Buddhist who refused Novocaine during a root canal? He wanted to transcend dental medication.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke-id  \\\n",
       "59        60   \n",
       "100      101   \n",
       "\n",
       "                                                                                                                      Text  \n",
       "59                                           What did the Buddhist say to the hot dog vendor? Make me one with everything.  \n",
       "100   Did you hear about the Buddhist who refused Novocaine during a root canal? He wanted to transcend dental medication.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke IDs:[58, 74]. Similarity score: 0.452843908367, Total votes: 3754\n",
      "Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>How many teddy bears does it take to change a lightbulb? It takes only one teddy bear, but it takes a whole lot of lightbulbs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>Q: How many stalkers does it take to change a light bulb? A: Two. One to replace the bulb, and the other to watch it day and night.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Joke-id  \\\n",
       "57       58   \n",
       "73       74   \n",
       "\n",
       "                                                                                                                                    Text  \n",
       "57        How many teddy bears does it take to change a lightbulb? It takes only one teddy bear, but it takes a whole lot of lightbulbs.  \n",
       "73   Q: How many stalkers does it take to change a light bulb? A: Two. One to replace the bulb, and the other to watch it day and night.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_df=jokes_sim_df[jokes_sim_df[\"Total-votes\"] > 1000].sort([\"Sim-score\"],ascending=[0]).head(5)\n",
    "print \"Top 5 jokes having highest similarity scores and rated by atleast 1000 users\"\n",
    "display(display_df)\n",
    "#display(jokes_sim_df[jokes_sim_df[\"Total-votes\"] > 1000].sort([\"Sim-score\"],ascending=[0]).tail(10))\n",
    "#pd.merge(left=jokes_sim_df,right= items_df, ignore_index=True)\n",
    "for a, b, c, d in list(zip(display_df[\"Joke-1\"],\n",
    "                           display_df[\"Joke-2\"],\n",
    "                           display_df[\"Sim-score\"],\n",
    "                           display_df[\"Total-votes\"])):\n",
    "    print \"Joke IDs:[{}, {}]. Similarity score: {}, Total votes: {}\".format(a,b,c,d)\n",
    "    print \"Text:\"\n",
    "    display(items_df[((items_df[\"Joke-id\"] == a) | (items_df[\"Joke-id\"] == b))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the related jokes identified, we can infer the following:\n",
    "* The joke IDs 123 and 140 are about Chuck Norris\n",
    "* The joke IDs 86 and 94 are about atoms/neutrons/electrons. Observe that these jokes do not share any topic words (neutron and atom/electron). The ID 86 is about neutron, while ID 94 is about atom/electron\n",
    "* The joke IDs 138 and 139 are about President George W. Bush\n",
    "* The joke IDs 60 and 101 are about a Buddhist\n",
    "* The joke IDs 58 and 74 are about light bulbs. Note the spelling of \"light bulb\". In the 58 joke ID it is spelled as \"lightbulb\" while 74 ID has \"light bulb\". But cosine similarity was able to find that these 2 jokes are related to each other based on the user ratings.\n",
    "\n",
    "Clearly, the cosine similarity measure is identifying the related joke pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Top 5 dissimilar jokes**\n",
    "\n",
    "Let us display the top 5 jokes which are dissimilar to each other. Here also we will consider only the jokes that were rated by at least 1000 users in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 dissimilar scores, based on the cosine similarity score:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-1</th>\n",
       "      <th>Joke-2</th>\n",
       "      <th>Sim-score</th>\n",
       "      <th>Total-votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>106</td>\n",
       "      <td>124</td>\n",
       "      <td>-0.065407</td>\n",
       "      <td>3768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8486</th>\n",
       "      <td>106</td>\n",
       "      <td>141</td>\n",
       "      <td>-0.065697</td>\n",
       "      <td>3730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6592</th>\n",
       "      <td>114</td>\n",
       "      <td>141</td>\n",
       "      <td>-0.076192</td>\n",
       "      <td>3774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8042</th>\n",
       "      <td>127</td>\n",
       "      <td>141</td>\n",
       "      <td>-0.076766</td>\n",
       "      <td>3769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>57</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.087814</td>\n",
       "      <td>4326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Joke-1  Joke-2  Sim-score  Total-votes\n",
       "1262     106     124  -0.065407         3768\n",
       "8486     106     141  -0.065697         3730\n",
       "6592     114     141  -0.076192         3774\n",
       "8042     127     141  -0.076766         3769\n",
       "4195      57     127  -0.087814         4326"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke IDs:[106, 124]. Similarity score: -0.065406866525, Total votes: 3768\n",
      "Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>An engineer dies and reports to the pearly gates. St. Peter checks his dossier and says, \"Ah, you''re an engineer--you're in the wrong place.\" So, the engineer reports to the gates of hell and is let in. Pretty soon, the engineer gets dissatisfied with the level of comfort in hell, and starts designing and building improvements. After awhile, they've got air conditioning, flush toilets and escalators, and the engineer is a pretty popular guy. One day, God calls Satan up on the telephone and says with a sneer, \"So, how's it going down there in hell?\" Satan replies, \"Hey, things are going great. We've got air conditioning, flush toilets and escalators, and there's no telling what this engineer is going to come up with next.\" God replies, \"What?? You've got an engineer? That's a mistake--he should never have gotten down there; send him up here.\" Satan says, \"No way.\" I like having an engineer on the staff, and I'm keeping him.\" God says, \"Send him back up here or I'll sue.\" Satan laughs uproariously and answers, \"Yeah, right. And just where are YOU going to get a lawyer?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>124</td>\n",
       "      <td>Person 1: Hey, wanna hear a great knock-knock joke? Person 2: Sure, What is it? Person 1: Okay, you start. Person 2: Knock-knock. Person 1: Who's there? Person 2: ... Person 1: Hah!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke-id  \\\n",
       "105      106   \n",
       "123      124   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Text  \n",
       "105   An engineer dies and reports to the pearly gates. St. Peter checks his dossier and says, \"Ah, you''re an engineer--you're in the wrong place.\" So, the engineer reports to the gates of hell and is let in. Pretty soon, the engineer gets dissatisfied with the level of comfort in hell, and starts designing and building improvements. After awhile, they've got air conditioning, flush toilets and escalators, and the engineer is a pretty popular guy. One day, God calls Satan up on the telephone and says with a sneer, \"So, how's it going down there in hell?\" Satan replies, \"Hey, things are going great. We've got air conditioning, flush toilets and escalators, and there's no telling what this engineer is going to come up with next.\" God replies, \"What?? You've got an engineer? That's a mistake--he should never have gotten down there; send him up here.\" Satan says, \"No way.\" I like having an engineer on the staff, and I'm keeping him.\" God says, \"Send him back up here or I'll sue.\" Satan laughs uproariously and answers, \"Yeah, right. And just where are YOU going to get a lawyer?\"  \n",
       "123                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Person 1: Hey, wanna hear a great knock-knock joke? Person 2: Sure, What is it? Person 1: Okay, you start. Person 2: Knock-knock. Person 1: Who's there? Person 2: ... Person 1: Hah!  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke IDs:[106, 141]. Similarity score: -0.06569676109, Total votes: 3730\n",
      "Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>An engineer dies and reports to the pearly gates. St. Peter checks his dossier and says, \"Ah, you''re an engineer--you're in the wrong place.\" So, the engineer reports to the gates of hell and is let in. Pretty soon, the engineer gets dissatisfied with the level of comfort in hell, and starts designing and building improvements. After awhile, they've got air conditioning, flush toilets and escalators, and the engineer is a pretty popular guy. One day, God calls Satan up on the telephone and says with a sneer, \"So, how's it going down there in hell?\" Satan replies, \"Hey, things are going great. We've got air conditioning, flush toilets and escalators, and there's no telling what this engineer is going to come up with next.\" God replies, \"What?? You've got an engineer? That's a mistake--he should never have gotten down there; send him up here.\" Satan says, \"No way.\" I like having an engineer on the staff, and I'm keeping him.\" God says, \"Send him back up here or I'll sue.\" Satan laughs uproariously and answers, \"Yeah, right. And just where are YOU going to get a lawyer?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>141</td>\n",
       "      <td>Jack Bauer can get McDonald's breakfast after 10:30.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke-id  \\\n",
       "105      106   \n",
       "140      141   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Text  \n",
       "105   An engineer dies and reports to the pearly gates. St. Peter checks his dossier and says, \"Ah, you''re an engineer--you're in the wrong place.\" So, the engineer reports to the gates of hell and is let in. Pretty soon, the engineer gets dissatisfied with the level of comfort in hell, and starts designing and building improvements. After awhile, they've got air conditioning, flush toilets and escalators, and the engineer is a pretty popular guy. One day, God calls Satan up on the telephone and says with a sneer, \"So, how's it going down there in hell?\" Satan replies, \"Hey, things are going great. We've got air conditioning, flush toilets and escalators, and there's no telling what this engineer is going to come up with next.\" God replies, \"What?? You've got an engineer? That's a mistake--he should never have gotten down there; send him up here.\" Satan says, \"No way.\" I like having an engineer on the staff, and I'm keeping him.\" God says, \"Send him back up here or I'll sue.\" Satan laughs uproariously and answers, \"Yeah, right. And just where are YOU going to get a lawyer?\"  \n",
       "140                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Jack Bauer can get McDonald's breakfast after 10:30.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke IDs:[114, 141]. Similarity score: -0.0761916493432, Total votes: 3774\n",
      "Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114</td>\n",
       "      <td>Sherlock Holmes and Dr. Watson go on a camping trip, set up their tent, and fall asleep. Some hours later, Holmes wakes his faithful friend. \"Watson, look up at the sky and tell me what you see.\"  Watson replies, \"I see millions of stars.\"  \"What does that tell you?\"  Watson ponders for a minute. \"Astronomically speaking, it tells me that there are millions of galaxies and potentially billions of planets. Astrologically, it tells me that Saturn is in Leo. Timewise, it appears to be approximately a quarter past three. Theologically, it's evident the Lord is all-powerful and we are small and insignificant. Meteorologically, it seems we will have a beautiful day tomorrow. What does it tell you?\"  Holmes is silent for a moment, then speaks. \"Watson, you idiot, someone has stolen our tent.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>141</td>\n",
       "      <td>Jack Bauer can get McDonald's breakfast after 10:30.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke-id  \\\n",
       "113      114   \n",
       "140      141   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Text  \n",
       "113   Sherlock Holmes and Dr. Watson go on a camping trip, set up their tent, and fall asleep. Some hours later, Holmes wakes his faithful friend. \"Watson, look up at the sky and tell me what you see.\"  Watson replies, \"I see millions of stars.\"  \"What does that tell you?\"  Watson ponders for a minute. \"Astronomically speaking, it tells me that there are millions of galaxies and potentially billions of planets. Astrologically, it tells me that Saturn is in Leo. Timewise, it appears to be approximately a quarter past three. Theologically, it's evident the Lord is all-powerful and we are small and insignificant. Meteorologically, it seems we will have a beautiful day tomorrow. What does it tell you?\"  Holmes is silent for a moment, then speaks. \"Watson, you idiot, someone has stolen our tent.\"  \n",
       "140                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Jack Bauer can get McDonald's breakfast after 10:30.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke IDs:[127, 141]. Similarity score: -0.0767660642306, Total votes: 3769\n",
      "Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>127</td>\n",
       "      <td>A little boy goes to his dad and asks, \"What is politics?\" His dad says, \"Well son, let me try to explain it this way: I'm the breadwinner of the family, so let's call me capitalism. Your Mom, she's the administrator of the money, so we'll call her the government. We're here to take care of your needs, so we'll call you the people. The nanny, we'll consider her the working class. And your baby brother, we'll call him the future. Now, think about that and see if that makes sense.\" So the little boy goes off to bed thinking about what dad had said. Later that night, he hears his baby brother crying, so he gets up to check on him. He finds that the baby has severely soiled his diaper. So the little boy goes to his parents' room and finds his mother sound asleep. Not wanting to wake her, he goes to the nanny's room. Finding the door locked, he peeks in the keyhole and sees his father in bed with the nanny. He gives up and goes back to bed. The next morning, the little boy says to his father, \"Dad, I think I understand the concept of politics now.\" The father says, \"Good, son. Tell me in your own words what you think politics is all about.\" The little boy replies, \"Well, while capitalism is screwing the working class, the government is sound asleep, the people are being ignored and the future is in deep shit.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>141</td>\n",
       "      <td>Jack Bauer can get McDonald's breakfast after 10:30.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke-id  \\\n",
       "126      127   \n",
       "140      141   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Text  \n",
       "126   A little boy goes to his dad and asks, \"What is politics?\" His dad says, \"Well son, let me try to explain it this way: I'm the breadwinner of the family, so let's call me capitalism. Your Mom, she's the administrator of the money, so we'll call her the government. We're here to take care of your needs, so we'll call you the people. The nanny, we'll consider her the working class. And your baby brother, we'll call him the future. Now, think about that and see if that makes sense.\" So the little boy goes off to bed thinking about what dad had said. Later that night, he hears his baby brother crying, so he gets up to check on him. He finds that the baby has severely soiled his diaper. So the little boy goes to his parents' room and finds his mother sound asleep. Not wanting to wake her, he goes to the nanny's room. Finding the door locked, he peeks in the keyhole and sees his father in bed with the nanny. He gives up and goes back to bed. The next morning, the little boy says to his father, \"Dad, I think I understand the concept of politics now.\" The father says, \"Good, son. Tell me in your own words what you think politics is all about.\" The little boy replies, \"Well, while capitalism is screwing the working class, the government is sound asleep, the people are being ignored and the future is in deep shit.\"  \n",
       "140                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Jack Bauer can get McDonald's breakfast after 10:30.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke IDs:[57, 127]. Similarity score: -0.087813975336, Total votes: 4326\n",
      "Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>Why are there so many Jones's in the phone book? Because they all have phones.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>127</td>\n",
       "      <td>A little boy goes to his dad and asks, \"What is politics?\" His dad says, \"Well son, let me try to explain it this way: I'm the breadwinner of the family, so let's call me capitalism. Your Mom, she's the administrator of the money, so we'll call her the government. We're here to take care of your needs, so we'll call you the people. The nanny, we'll consider her the working class. And your baby brother, we'll call him the future. Now, think about that and see if that makes sense.\" So the little boy goes off to bed thinking about what dad had said. Later that night, he hears his baby brother crying, so he gets up to check on him. He finds that the baby has severely soiled his diaper. So the little boy goes to his parents' room and finds his mother sound asleep. Not wanting to wake her, he goes to the nanny's room. Finding the door locked, he peeks in the keyhole and sees his father in bed with the nanny. He gives up and goes back to bed. The next morning, the little boy says to his father, \"Dad, I think I understand the concept of politics now.\" The father says, \"Good, son. Tell me in your own words what you think politics is all about.\" The little boy replies, \"Well, while capitalism is screwing the working class, the government is sound asleep, the people are being ignored and the future is in deep shit.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke-id  \\\n",
       "56        57   \n",
       "126      127   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Text  \n",
       "56                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Why are there so many Jones's in the phone book? Because they all have phones.  \n",
       "126   A little boy goes to his dad and asks, \"What is politics?\" His dad says, \"Well son, let me try to explain it this way: I'm the breadwinner of the family, so let's call me capitalism. Your Mom, she's the administrator of the money, so we'll call her the government. We're here to take care of your needs, so we'll call you the people. The nanny, we'll consider her the working class. And your baby brother, we'll call him the future. Now, think about that and see if that makes sense.\" So the little boy goes off to bed thinking about what dad had said. Later that night, he hears his baby brother crying, so he gets up to check on him. He finds that the baby has severely soiled his diaper. So the little boy goes to his parents' room and finds his mother sound asleep. Not wanting to wake her, he goes to the nanny's room. Finding the door locked, he peeks in the keyhole and sees his father in bed with the nanny. He gives up and goes back to bed. The next morning, the little boy says to his father, \"Dad, I think I understand the concept of politics now.\" The father says, \"Good, son. Tell me in your own words what you think politics is all about.\" The little boy replies, \"Well, while capitalism is screwing the working class, the government is sound asleep, the people are being ignored and the future is in deep shit.\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_df=jokes_sim_df[jokes_sim_df[\"Total-votes\"] > 1000].sort([\"Sim-score\"],ascending=[0]).tail(5)\n",
    "print \"Top 5 dissimilar scores, based on the cosine similarity score:\"\n",
    "display(display_df)\n",
    "#display(jokes_sim_df[jokes_sim_df[\"Total-votes\"] > 1000].sort([\"Sim-score\"],ascending=[0]).tail(10))\n",
    "#pd.merge(left=jokes_sim_df,right= items_df, ignore_index=True)\n",
    "for a, b, c, d in list(zip(display_df[\"Joke-1\"],display_df[\"Joke-2\"],display_df[\"Sim-score\"],\n",
    "                           display_df[\"Total-votes\"])):\n",
    "    print \"Joke IDs:[{}, {}]. Similarity score: {}, Total votes: {}\".format(a,b,c,d)\n",
    "    print \"Text:\"\n",
    "    display(items_df[((items_df[\"Joke-id\"] == a) | (items_df[\"Joke-id\"] == b))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Looking at the text of these joke pairs, we can infer that they are entirely different from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Making recommendations using cosine similarity measure\n",
    "Let us make recommendations for some of the users based on the jokes they rated high. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rows of the ratings data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Joke_ID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-9.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-6.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID  Joke_ID  Rating\n",
       "0        1        5   0.219\n",
       "1        1        7  -9.281\n",
       "2        1        8  -9.281\n",
       "3        1       13  -6.781\n",
       "4        1       15   0.875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Reading the ratings data set to a file\n",
    "ratings_df = pd.read_csv(\"jester_ratings.dat\",sep=\"\\t\\t\",header=None)\n",
    "ratings_df.columns = [\"User_ID\", \"Joke_ID\",\"Rating\"]\n",
    "print \"Initial rows of the ratings data:\"\n",
    "display(ratings_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a function that takes a user ID as input and recommends some jokes based on the jokes s/he has rated high. The recommended jokes were not already rated by the user. \n",
    "\n",
    "**NOTE** I assumed that a person likes a joke, whenever he gives a rating greater than 5. The default rating is 0 (see the website http://eigentaste.berkeley.edu/. The rating's slider bar stays at 0, if the user does not give any rating), +10 is the best possible rating and -10 is the least possible rating. So, I chose 5 as the minimum rating to determine if the user really likes the jokes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_recommendations(user_id,ratings_df,top_n,jokes_sim_df,items_df):\n",
    "    #Get the top 5 jokes which the user has rated:\n",
    "    top_user_ratings = ratings_df[(ratings_df[\"User_ID\"] == user_id) & (ratings_df[\"Rating\"] > 5)\n",
    "                                 ].sort([\"Rating\"],ascending=[0]).head(5)\n",
    "    \n",
    "    print \"The user ID: {} has rated these jokes high:\".format(user_id)\n",
    "    display(top_user_ratings)\n",
    "    \n",
    "    #for a in list(top_user_ratings[\"Joke_ID\"]):\n",
    "        #display(items_df[items_df[\"Joke-id\"] == a])\n",
    "    display(items_df[items_df[\"Joke-id\"].isin(list(top_user_ratings[\"Joke_ID\"]))])    \n",
    "    #print \"Joke IDs:[{}, {}]. Similarity score: {}, Total votes: {}\".format(a,b,c,d)\n",
    "    #print \"Text:\"\n",
    "    #display(items_df[((items_df[\"Joke-id\"] == a) | (items_df[\"Joke-id\"] == b))])\n",
    "    \n",
    "    #Get the jokes which were already rated by the user\n",
    "    already_rated = list(ratings_df[(ratings_df[\"User_ID\"] == user_id)][\"Joke_ID\"])\n",
    "    recommend_list=list()\n",
    "    #Get the top recommendations for the user ID:\n",
    "    for i in list(top_user_ratings[\"Joke_ID\"]):\n",
    "        recommend_list.append(list(jokes_sim_df[\n",
    "                (jokes_sim_df[\"Joke-1\"] == i) & (jokes_sim_df[\"Total-votes\"] > 1000)\n",
    "                 & ~(jokes_sim_df[\"Joke-2\"].isin(already_rated))   \n",
    "                ].sort([\"Sim-score\"],ascending=[0]).head(1)[\"Joke-2\"]))\n",
    "        recommend_list.append(list(jokes_sim_df[\n",
    "                (jokes_sim_df[\"Joke-2\"] == i) & (jokes_sim_df[\"Total-votes\"] > 1000)\n",
    "                 & ~(jokes_sim_df[\"Joke-1\"].isin(already_rated))\n",
    "                ].sort([\"Sim-score\"],ascending=[0]).head(1)[\"Joke-1\"]))\n",
    "    recommend_list = [i for i in recommend_list if len(i) > 0]\n",
    "    #print recommend_list\n",
    "    recommend_list = [item for sublist in recommend_list for item in sublist]\n",
    "    #recommendations = list(recommendations.difference(already_rated))\n",
    "    \n",
    "    print \"Here are the recommended items for the user ID: {}\".format(user_id)\n",
    "    \n",
    "    display(items_df[items_df[\"Joke-id\"].isin(recommend_list)])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting recommendations for user ID 17 (a random user ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user ID: 17 has rated these jokes high:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Joke_ID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>9.938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     User_ID  Joke_ID  Rating\n",
       "755       17       17  10.000\n",
       "771       17       49  10.000\n",
       "758       17       20  10.000\n",
       "766       17       35  10.000\n",
       "751       17        8   9.938"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Q. Did you hear about the dyslexic devil worshiper? A. He sold his soul to Santa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>How many men does it take to screw in a light bulb? One. Men will screw anything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>What's the difference between a Macintosh and an Etch-a-Sketch? You don't have to shake the Mac to clear the screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>An explorer in the deepest Amazon suddenly finds himself surrounded by a bloodthirsty group of natives. Upon surveying the situation, he says quietly to himself, \"Oh God, I'm screwed.\" The sky darkens and a voice booms out, \"No, you are NOT screwed. Pick up that stone at your feet and bash in the head of the chief standing in front of you.\" So with the stone he bashes the life out of the chief. He stands above the lifeless body, breathing heavily and looking at 100 angry natives... The voice booms out again, \"Okay....NOW you're screwed.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>Three engineering students were gathered together discussing the possible designers of the human body. One said, \"It was a mechanical engineer. Just look at all the joints.\" Another said, \"No, it was an electrical engineer. The nervous systems many thousands of electrical connections.\" The last said, \"Actually, it was a civil engineer. Who else would run a toxic waste pipeline through a recreational area?\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Joke-id  \\\n",
       "7         8   \n",
       "16       17   \n",
       "19       20   \n",
       "34       35   \n",
       "48       49   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Text  \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Q. Did you hear about the dyslexic devil worshiper? A. He sold his soul to Santa.  \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 How many men does it take to screw in a light bulb? One. Men will screw anything.  \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                                              What's the difference between a Macintosh and an Etch-a-Sketch? You don't have to shake the Mac to clear the screen.  \n",
       "34   An explorer in the deepest Amazon suddenly finds himself surrounded by a bloodthirsty group of natives. Upon surveying the situation, he says quietly to himself, \"Oh God, I'm screwed.\" The sky darkens and a voice booms out, \"No, you are NOT screwed. Pick up that stone at your feet and bash in the head of the chief standing in front of you.\" So with the stone he bashes the life out of the chief. He stands above the lifeless body, breathing heavily and looking at 100 angry natives... The voice booms out again, \"Okay....NOW you're screwed.\"  \n",
       "48                                                                                                                                         Three engineering students were gathered together discussing the possible designers of the human body. One said, \"It was a mechanical engineer. Just look at all the joints.\" Another said, \"No, it was an electrical engineer. The nervous systems many thousands of electrical connections.\" The last said, \"Actually, it was a civil engineer. Who else would run a toxic waste pipeline through a recreational area?\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the recommended items for the user ID: 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>A guy walks into a bar and sits down next to an extremely gorgeous woman. The first thing he notices about her though, are her pants. They were skin-tight, high-waisted and had no obvious mechanism (zipper, buttons or velcro) for opening them.  After several minutes of puzzling over how she got the pants up over her hips, he finally worked up the nerve to ask her. \"Excuse me miss, but how do you get into your pants?\"  \"Well,\" she replied, \"you can start by buying me a drink.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>What is the difference between men and women? A woman wants one man to satisfy her every need. A man wants every woman to satisfy his one need.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>There was an engineer who had an exceptional gift for fixing all things mechanical. After serving his company loyally for over 30 years, he happily retired. Several years later the company contacted him regarding a seemingly impossible problem they were having with one of their multi-million dollar machines. They had tried everything and everyone else to get the machine fixed, but to no avail. In desperation, they called on the retired engineer who had solved so many of their problems in the past. The engineer reluctantly took the challenge. He spent a day studying the huge machine. At the end of the day, he marked a small \"x\" in chalk on a particular component of the machine and proudly stated \"This is where your problem is.\" The part was replaced and the machine worked perfectly again. The company received a bill for $50,000 from the engineer for his service. They demanded an itemized accounting of his charges. The engineer responded briefly One chalk mark: $1. Knowing where to put it: $49,999. He was paid in full and the engineer retired again in peace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>What is the rallying cry of the International Dyslexic Pride movement? Dyslexics Untie!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>105</td>\n",
       "      <td>A couple of hunters are out in the woods in the deep south when one of them falls to the ground. He doesn't seem to be breathing, and his eyes are rolled back in his head. The other guy whips out his cell phone and calls 911. He gasps to the operator, \"My friend is dead! What can I do?\" The operator, in a calm and soothing voice, says, \"Alright, take it easy. I can help. First, let's make sure he's dead.\" There is silence, and then a gun shot is heard. The hunter comes back on the line. \"Okay. Now what??\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>126</td>\n",
       "      <td>A Briton, a Frenchman and a Russian are viewing a painting of Adam and Eve frolicking in the Garden of Eden. \"Look at their reserve, their calm,\" muses the Brit. \"They must be British.\" \"Nonsense,\" the Frenchman disagrees. \"They're naked, and so beautiful. Clearly, they are French.\" \"No way! They have no clothes and no shelter,\" the Russian points out, \"They have only an apple to eat, and they are being told they live in a paradise. Obviously, they are Russian.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke-id  \\\n",
       "25        26   \n",
       "38        39   \n",
       "46        47   \n",
       "63        64   \n",
       "104      105   \n",
       "125      126   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Text  \n",
       "25                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    A guy walks into a bar and sits down next to an extremely gorgeous woman. The first thing he notices about her though, are her pants. They were skin-tight, high-waisted and had no obvious mechanism (zipper, buttons or velcro) for opening them.  After several minutes of puzzling over how she got the pants up over her hips, he finally worked up the nerve to ask her. \"Excuse me miss, but how do you get into your pants?\"  \"Well,\" she replied, \"you can start by buying me a drink.\"  \n",
       "38                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     What is the difference between men and women? A woman wants one man to satisfy her every need. A man wants every woman to satisfy his one need.  \n",
       "46    There was an engineer who had an exceptional gift for fixing all things mechanical. After serving his company loyally for over 30 years, he happily retired. Several years later the company contacted him regarding a seemingly impossible problem they were having with one of their multi-million dollar machines. They had tried everything and everyone else to get the machine fixed, but to no avail. In desperation, they called on the retired engineer who had solved so many of their problems in the past. The engineer reluctantly took the challenge. He spent a day studying the huge machine. At the end of the day, he marked a small \"x\" in chalk on a particular component of the machine and proudly stated \"This is where your problem is.\" The part was replaced and the machine worked perfectly again. The company received a bill for $50,000 from the engineer for his service. They demanded an itemized accounting of his charges. The engineer responded briefly One chalk mark: $1. Knowing where to put it: $49,999. He was paid in full and the engineer retired again in peace.  \n",
       "63                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             What is the rallying cry of the International Dyslexic Pride movement? Dyslexics Untie!  \n",
       "104                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     A couple of hunters are out in the woods in the deep south when one of them falls to the ground. He doesn't seem to be breathing, and his eyes are rolled back in his head. The other guy whips out his cell phone and calls 911. He gasps to the operator, \"My friend is dead! What can I do?\" The operator, in a calm and soothing voice, says, \"Alright, take it easy. I can help. First, let's make sure he's dead.\" There is silence, and then a gun shot is heard. The hunter comes back on the line. \"Okay. Now what??\"  \n",
       "125                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 A Briton, a Frenchman and a Russian are viewing a painting of Adam and Eve frolicking in the Garden of Eden. \"Look at their reserve, their calm,\" muses the Brit. \"They must be British.\" \"Nonsense,\" the Frenchman disagrees. \"They're naked, and so beautiful. Clearly, they are French.\" \"No way! They have no clothes and no shelter,\" the Russian points out, \"They have only an apple to eat, and they are being told they live in a paradise. Obviously, they are Russian.\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_recommendations(17,ratings_df,5,jokes_sim_df,items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User ID 17 liked the joke ID 17 (about men), and the system has recommended joke ID 39 (which is also about men). Similarly, the joke ID 8 (liked joke) and joke ID 64 (recommended joke) are related (both refer to Dyslexic). Jokes 20 (liked joke) and 39 (recommended joke) are also related, since both are worded similarly \"what is the difference between ... \". Joke ID 35 (liked joke) and 105 (recommended joke) are also related both refer to hunters/explorers, killing someone etc. Joke ID 49 (liked joke) and 47 (recommended joke) are related, since both refer to engineer(s). Joke ID 49 (liked joke) and 126 (recommended joke) are also related, since both jokes refer to a series of reasons to determine \"who should be or have made something...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the recommendations for the user ID 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user ID: 1000 has rated these jokes high:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Joke_ID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38207</th>\n",
       "      <td>1000</td>\n",
       "      <td>15</td>\n",
       "      <td>9.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38208</th>\n",
       "      <td>1000</td>\n",
       "      <td>16</td>\n",
       "      <td>9.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38209</th>\n",
       "      <td>1000</td>\n",
       "      <td>17</td>\n",
       "      <td>9.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38210</th>\n",
       "      <td>1000</td>\n",
       "      <td>18</td>\n",
       "      <td>9.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38211</th>\n",
       "      <td>1000</td>\n",
       "      <td>19</td>\n",
       "      <td>9.031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       User_ID  Joke_ID  Rating\n",
       "38207     1000       15   9.031\n",
       "38208     1000       16   9.031\n",
       "38209     1000       17   9.031\n",
       "38210     1000       18   9.031\n",
       "38211     1000       19   9.031"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Q: What did the blind person say when given some matzah? A: Who the hell wrote this?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Q. What is orange and sounds like a parrot? A. A carrot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>How many men does it take to screw in a light bulb? One. Men will screw anything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>A dog walks into Western Union and asks the clerk to send a telegram. He fills out a form on which he writes down the telegram he wishes to send: \"Bow wow wow, bow wow wow.\" The clerk says, \"You can add another 'Bow wow' for the same price.\" The dog responded, \"Now wouldn't that sound a little silly?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Q: If a person who speaks three languages is called \"trilingual,\" and a person who speaks two languages is called \"bilingual,\" what do you call a person who only speaks one language? A: American!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Joke-id  \\\n",
       "14       15   \n",
       "15       16   \n",
       "16       17   \n",
       "17       18   \n",
       "18       19   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                               Text  \n",
       "14                                                                                                                                                                                                                             Q: What did the blind person say when given some matzah? A: Who the hell wrote this?  \n",
       "15                                                                                                                                                                                                                                                         Q. What is orange and sounds like a parrot? A. A carrot.  \n",
       "16                                                                                                                                                                                                                                How many men does it take to screw in a light bulb? One. Men will screw anything.  \n",
       "17   A dog walks into Western Union and asks the clerk to send a telegram. He fills out a form on which he writes down the telegram he wishes to send: \"Bow wow wow, bow wow wow.\" The clerk says, \"You can add another 'Bow wow' for the same price.\" The dog responded, \"Now wouldn't that sound a little silly?\"  \n",
       "18                                                                                                              Q: If a person who speaks three languages is called \"trilingual,\" and a person who speaks two languages is called \"bilingual,\" what do you call a person who only speaks one language? A: American!  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the recommended items for the user ID: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>What do you get when you run over a parakeet with a lawnmower? Shredded tweet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>What is the difference between men and women? A woman wants one man to satisfy her every need. A man wants every woman to satisfy his one need.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>A horse walks into a bar. The bartender asks \"So, why the long face?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>Why are there so many Jones's in the phone book? Because they all have phones.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>138</td>\n",
       "      <td>WASHINGTON (Reuters) - A tragic fire on Monday destroyed the personal library of President George W. Bush. Both of his books have been lost. Presidential spokesman Ari Fleischer said the president was devastated, as he had not finished coloring the second one.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke-id  \\\n",
       "23        24   \n",
       "38        39   \n",
       "43        44   \n",
       "56        57   \n",
       "137      138   \n",
       "\n",
       "                                                                                                                                                                                                                                                                      Text  \n",
       "23                                                                                                                                                                                          What do you get when you run over a parakeet with a lawnmower? Shredded tweet.  \n",
       "38                                                                                                                         What is the difference between men and women? A woman wants one man to satisfy her every need. A man wants every woman to satisfy his one need.  \n",
       "43                                                                                                                                                                                                   A horse walks into a bar. The bartender asks \"So, why the long face?\"  \n",
       "56                                                                                                                                                                                          Why are there so many Jones's in the phone book? Because they all have phones.  \n",
       "137   WASHINGTON (Reuters) - A tragic fire on Monday destroyed the personal library of President George W. Bush. Both of his books have been lost. Presidential spokesman Ari Fleischer said the president was devastated, as he had not finished coloring the second one.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_recommendations(1000,ratings_df,5,jokes_sim_df,items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user ID 1000 liked the joke ID 18 (about a dog), and the system has recommended joke ID 44 (about a horse). Also, it looks like the user like jokes which are more like interrogative statements or questions, and the recommended jokes are also of the same form (except the joke ID 138). \n",
    "\n",
    "Given the above recommendations, we can infer that the cosine similarity is doing a decent job. However, we have the drawbacks with this recommender system:\n",
    "\n",
    "1. For a new user, we do not have a good mechanism to provide recommendations (the cold start problem).\n",
    "\n",
    "2. We assumed that a rating of greater than 5 implies that the user has really liked the joke. This assumption might be incorrect. Based on this criteria, we may not have any jokes to recommend, if a user gives a rating of less than 5 for all the jokes s/he reads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, we can represent the complete work flow of the collaborative filtering recommender developed above in the form of a flow chart given below:\n",
    "\n",
    "#### Fig-1: Cosine similarity based recommender work-flow\n",
    "<img src=\"process-1.png\">\n",
    "\n",
    "**Steps**\n",
    "1.\tThe _Ratings Dataset_ is supplied as input to the PySpark program (in _Appendix-B_)\n",
    "2.\tThe PySpark program produces a file _Cosine Similarity dataset_ with cosine similarity scores between the jokes, which are rated in common by at least one user\n",
    "3.\tThe *get_recommendations()* is called with the Cosine Similarity Scores and user ID as inputs\n",
    "4.\tThe *get_recommendations()* function will use Ratings Dataset to determine the items, which were already liked by the user\n",
    "5.\tBased on the items which were liked by the user, the *get_recommendations()* function will  recommend items to the user\n",
    "6.\tCheck if the user updates the item ratings\n",
    "7.\tIf user updates any item ratings (implicit or explicit updates), update the *Ratings Dataset* and call *get_recommendations()* again\n",
    "8.\tIf the user does not update any item ratings take no action.\n",
    "\n",
    "In the above workflow, we did not discuss how often we should re-compute the cosine similarity scores. The frequency of similarity scores update depends on what percentage of ratings are updated by the users and the available computing resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender system - 2\n",
    "\n",
    "Our second recommender system is based on Stochastic Gradient Descent algorithm. \n",
    "\n",
    "### Stochastic Gradient Descent \n",
    "We will now evaluate the SGD (Stochastic Gradient Descent) method to factorize the user-item ratings (utility matrix) to predict the ratings a user could give to a joke he never read.\n",
    "\n",
    "In recommendation systems, we have a Utility matrix that shows the affinity of all users towards all available items. But this Utility matrix is very sparse, since most of the users might not have looked or experienced all items, and the main goal of recommender systems is to identify the potential items the user might be interested in, by predicting the missing elements (or ratings) in the Utility matrix. One way to accomplish this goal is based on matrix factorization method. In matrix factorization method, we must express the Utility matrix as a product of two matrices, in order to estimate the missing entries in the Utility matrix. In mathematical terms, we define our main objective as given below. \n",
    "\n",
    "_Objective_: Express the matrix M as a product of U and V. Where _M_ is a _mXn_ matrix, _U_ is a _mXd_ matrix and _V_ is a _dXn_ matrix, and _d_ is the number of latent factors. \n",
    "\n",
    "\n",
    "Mathematically, let\n",
    "$$M=\\left[ \\begin{array}{cccccc} r_{11} & r_{12} & . & . & r_{1n} \\\\ r_{21} & r_{22} & . & . & r_{2n} \\\\ r_{31} & r_{32} & . & . & r_{3n} \\\\ . & . & . & . & . \\\\  . & . & . & . & . \\\\ r_{m1} & r_{m2} & . & . & r_{mn} \\end{array} \\right]$$\n",
    "$$U=\\left[ \\begin{array}{ccc} u_{11} & . & u_{1d} \\\\ u_{21} & . & u_{2d} \\\\  u_{31} & . & u_{3d} \\\\ . & . & . \\\\ .& . & . \\\\ u_{m1} & . & u_{md} \\end{array} \\right]$$ \n",
    "$$V=\\left[ \\begin{array}{ccccc} v_{11} & v_{12} & . & . & v_{1n} \\\\ v_{21} & v_{22} & . & . & v_{2n} \\\\ . & . & . & . & . \\\\v_{d1} & v_{d2} & . & . & v_{dn}\\end{array} \\right]\n",
    "$$\n",
    "\n",
    "Then M can be expressed as the matrix product of U and V, as shown below: \n",
    "$$\\left[ \\begin{array}{cccccc} r_{11} & r_{12} & . & . & r_{1n} \\\\ r_{21} & r_{22} & . & . & r_{2n} \\\\ r_{31} & r_{32} & . & . & r_{3n} \\\\ . & . & . & . & . \\\\  . & . & . & . & . \\\\ r_{m1} & r_{m2} & . & . & r_{mn} \\end{array} \\right] \\approx \n",
    "\\left[ \\begin{array}{ccc} u_{11} & . & u_{1d} \\\\ u_{21} & . & u_{2d} \\\\  u_{31} & . & u_{3d} \\\\ . & . & . \\\\ .& . & . \\\\ u_{m1} & . & u_{md} \\end{array} \\right] \\left[ \\begin{array}{ccccc} v_{11} & v_{12} & . & . & v_{1n} \\\\ v_{21} & v_{22} & . & . & v_{2n} \\\\ . & . & . & . & . \\\\v_{d1} & v_{d2} & . & . & v_{dn}\\end{array} \\right] $$\n",
    "\n",
    "In recommender systems, the matrix M is a sparse matrix with many unknown entries. An example of such sparse matrix is shown below:\n",
    "\n",
    "$$M=\\left[ \\begin{array}{cccccc}  & r_{12} & . & . & r_{1n} \\\\ r_{21} &   & . & . & r_{2n} \\\\ r_{31} &   & . & . &   \\\\ . & . & . & . & . \\\\  . & . & . & . & . \\\\ r_{m1} & r_{m2} & . & . &   \\end{array} \\right]$$\n",
    "\n",
    "For such sparse matrices, we cannot use SVD (Singular Value Decomposition) method to factorize the matrix. Hence for recommendation systems, our main objective is to estimate the U and V matrices considering only the available data in M. Once we obtain optimal U and V matrices (based on the available data in M), we can get the matrix product UV, and estimate an approximate value of the missing elements in M, by comparing the corresponding elements between M and UV. Another advantage of U, V factorization is to identify the hidden dimensions (also called latent factors), which map both the user and items to a common set of dimensions/coordinate system. Such mapping will help to identify users/items/user-item pairs, which are near to each other.\n",
    "\n",
    "Two of the prominent methods to estimate the U and V matrices are: \n",
    "\n",
    "* Alternating Least Squares (ALS) \n",
    "\n",
    "* Gradient descent method (Stochastic Gradient Descent or SGD)\n",
    "\n",
    "Spark MLLib has a built-in ALS implementation. But for this project we will use SGD implemented on a non-distributed environment. The goal is to check if SGD can be used on the 1.7 Million ratings data set in a non-distributed environment (a laptop with 16GB RAM), and evaluate the performance of the SGD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD algorithm\n",
    "\n",
    "1. Initialize U and V to random values. We can assume 0s for NA values in M, use SVD method to obtain U and V, and use these values as the initial values of U and V.\n",
    "\n",
    "2. Randomly choose U or V\n",
    "\n",
    "3. If U is chosen, randomly choose a row _i_ from U. To estimate the row $U_i$, perform the following:\n",
    "\n",
    "   3a. Get the list of all columns in $M_i$ row, where we have available values. Call these locations as C\n",
    "\n",
    "   3b. Let $V_C = V[:,C]$, where $V[:,C]$ is the list of all columns in V, corresponding to the column numbers present in C\n",
    "   \n",
    "   3c. Estimate new value of $U_i$ as:\n",
    "$$U^{new}_{i} = U_{i} - \\alpha \\nabla_{U_{i}} f_{ij}(U_i,V_i)$$ where $\\alpha$ is the learning rate, and $\\nabla_{U_i}f_{ij}(U_i,V_j)$ is defined as follows:\n",
    "$$\\nabla_{U_i}f_{ij}(U_i,V_j) = [M_i - U_i.V_C].V_C^T + \\lambda_1 U_i$$ where $\\lambda_1$ is the regularization parameter\n",
    "\n",
    "4. If V is chosen, randomly choose a column _j_ from V. To estimate the column $V_j$, perform the following:\n",
    "\n",
    "   4a. Get the list of all rows in $M_j$ column, where we have available values. Call these locations as R\n",
    "\n",
    "   4b. Let $U_R = U[R,:]$, where $U[R,:]$ is the list of all rows in U, corresponding to the row numbers present in R\n",
    "   \n",
    "   4c. Estimate new value of $V_j$ as:\n",
    "$$V^{new}_{j} = V_{j} - \\alpha \\nabla_{V_{j}} f_{ij}(U_i,V_i)$$ where $\\alpha$ is the learning rate, and $\\nabla_{V_{j}}f_{ij}(U_i,V_j)$ is defined as follows:\n",
    "$$\\nabla_{V_{j}}f_{ij}(U_i,V_j) = [M_j - U_R.V_j]^T.U_R + \\lambda_2 V_j$$ where $\\lambda_2$ is the regularization parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of SGD\n",
    "\n",
    "We will code the following 4 functions to compute U and V using SGD method:\n",
    "\n",
    "**SGD_factorization(M,d, lambda1, lambda2, n, error_diff, seed,alpha)**\n",
    "In SGD we will estimate the row of U or column of V by choosing randomly U or V and choosing the row from U or column from V randomly. The randomness in choosing the elements is important. The function SGD_factorization function will accept 8 parameters. The first parameter is M (utility matrix), the second parameter is _d_ (the desired number of latent factors), the third parameter is _lambda1_ (regularization factor for computing U's row), _lambda2_ (regularization factor for computing V's column), _n_ is the maximum number of iterations, and *error_diff* is the least acceptable error difference between the consecutive iterations, _seed_ will accept a number which can be used to reproduce the results, and _alpha_ is the learning rate. The algorithm stops updating the elements of U and V once the specified number of iterations is reached or when the error difference between consecutive iterations is less than or equal to *error_diff*\n",
    "\n",
    "\n",
    "**SGD_compute_U_row(i,M,V,d,lambda1)**\n",
    "This function will accept 5 variables as inputs, and computes the gradient for a specific row in U, while keeping all other U and V elements constant. The parameters details are given below:\n",
    "\n",
    "i = desired row number in U that needs to be estimated (row numbers begin from 0)\n",
    "\n",
    "M = Utility matrix, which needs to be factorized\n",
    "\n",
    "V = V matrix or factor in the expression M = UV\n",
    "\n",
    "d = desired number of latent factors or columns in U\n",
    "\n",
    "lambda1 = regularization parameter\n",
    "\n",
    "\n",
    "**SGD_compute_V_col(j,M,U,d,lambda2)**\n",
    "This function will also accept 5 variables as inputs, and computes the gradient for a specific column in V, while keeping all other U and V elements constant. The parameters details are given below:\n",
    "\n",
    "j = desired column number in V that needs to be estimated (column numbers begin from 0)\n",
    "\n",
    "M = Utility matrix, which needs to be factorized\n",
    "\n",
    "U = U matrix or factor in the expression M = UV\n",
    "\n",
    "d = desired number of latent factors or rows in V\n",
    "\n",
    "lambda2 = regularization parameter\n",
    "\n",
    "**get_RMSE_error(M,U,V)**\n",
    "This function will compute the RMSE between M and UV, considering the available elements only in M. Takes 3 parameters M, U and V. M is the Utility matrix, U is the U component and V is the V component in M = UV. \n",
    "\n",
    "The following block implements the SGD algorithm in Python 2.7. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_RMSE(M,U,V):\n",
    "    return np.sqrt(np.nanmean(np.square(M - np.dot(U,V))))\n",
    "\n",
    "def SGD_compute_U_row(i,M,U,V,d,lambda1,alpha):\n",
    "    '''\n",
    "     i = desired row number in U, which needs to be computed\n",
    "     M = Utility matrix of size mXn\n",
    "     V = V component of size dXn\n",
    "     lambda1 = reg factor\n",
    "    '''\n",
    "    num_of_rows, num_of_cols = M.shape\n",
    "   \n",
    "    #np.where will return a tuple.\n",
    "    C = np.where(~np.isnan(M[i,]))[0]\n",
    "    \n",
    "    V_C = V[:,C].copy()\n",
    "    M_i = M[i,:].copy()\n",
    "    M_i = M_i[~np.isnan(M_i)]\n",
    "    return alpha*(-1*np.dot((M_i - np.dot(U[i,],V_C)),V_C.T) + lambda1 * U[i,])\n",
    "    \n",
    "def SGD_compute_V_col(j,M,U,V,d,lambda2,alpha):\n",
    "    '''\n",
    "     j = desired column number in V, which needs to be computed\n",
    "     M = Utility matrix of size mXn\n",
    "     U = U component of size mXd\n",
    "     lambda2 = reg factor\n",
    "    '''\n",
    "    num_of_rows, num_of_cols = M.shape\n",
    "    \n",
    "    #np.where will return a tuple.\n",
    "    R = np.where(~np.isnan(M[:,j]))[0]\n",
    "    \n",
    "    U_R = U[R,:].copy()\n",
    "    M_j = M[:,j].copy()\n",
    "    M_j = M_j[~np.isnan(M_j)]\n",
    "    return alpha*(-1*np.dot((M_j - np.dot(U_R,V[:,j])).T,U_R) + lambda2 * V[:,j])\n",
    "\n",
    "\n",
    "def SGD_factorization(M,d, lambda1, lambda2, n, error_diff, seed,alpha):\n",
    "    import numpy as np\n",
    "    #Initialize U and V\n",
    "    M_rows, M_cols = M.shape\n",
    "    M_non_nan = np.nan_to_num(M)\n",
    "\n",
    "    U, s, vt = svds(M_non_nan, k=d, ncv=None, tol=0, which='LM', \n",
    "                             v0=None, maxiter=None, return_singular_vectors=True)\n",
    "    #print U\n",
    "    #print np.dot(np.diag(s),vt)\n",
    "    #print vt\n",
    "    V = np.dot(np.diag(s),vt)\n",
    "    #print \"In SGD Factorization...\"\n",
    "    #print \"U.shape:{}\".format(U.shape)\n",
    "    #print \"V.shape:{}\".format(V.shape)\n",
    "    \n",
    "    #print V\n",
    "    #np.random.seed(seed)\n",
    "    #U = np.zeros((M_rows,d),dtype=np.float)+np.random.rand(M_rows,d)\n",
    "    #np.random.seed(seed)\n",
    "    #V = np.zeros((d,M_cols),dtype=np.float)+np.random.rand(d,M_cols)\n",
    "    error = []\n",
    "    error.append(get_RMSE(M,U,V))\n",
    "\n",
    "    for count in xrange(n):\n",
    "            #Do not use any seed here\n",
    "            #pick_1 = np.random.random_integers(0,1)\n",
    "            pick_1 = np.random.randint(0,2)\n",
    "            if pick_1 == 0:\n",
    "                #pick_2 = np.random.random_integers(0,M_rows - 1)\n",
    "                pick_2 = np.random.randint(0,M_rows)\n",
    "                U[pick_2,] = U[pick_2,] - SGD_compute_U_row(pick_2,M,U,V,d,lambda1,alpha)\n",
    "                error.append(get_RMSE(M,U,V))\n",
    "                if np.absolute(error[-2] - error[-1]) <= error_diff:\n",
    "                    return [U, V, error]\n",
    "            else:\n",
    "                #pick_2 = np.random.random_integers(0,M_cols-1)\n",
    "                pick_2 = np.random.randint(0,M_cols)\n",
    "                V[:,pick_2] = V[:,pick_2] - SGD_compute_V_col(pick_2,M,U,V,d,lambda2,alpha)\n",
    "                error.append(get_RMSE(M,U,V))        \n",
    "                if np.absolute(error[-2] - error[-1]) <= error_diff:\n",
    "                    return [U, V, error]\n",
    "    return [U, V, error]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a framework to measure the SGD's performance \n",
    "\n",
    "We need to build the following functions to successfully evaluate the algorithm's performance:\n",
    "\n",
    "* Select a desired number of users randomly. This will help us to test the scalability of our algorithm for different volumes of data, since number of users selected is proportional to the amount of data used.\n",
    "\n",
    "* Create a Utility matrix based on the selected users-rating data.\n",
    "\n",
    "* The Utility matrix, will be split into test and training data (20:80 for test:training respectively). A function will be written to perform this split. If only one rating is available for an item, the function must eliminate such item's rating from test data. The split must be random.\n",
    "\n",
    "* Define a function to obtain the rating present at the intersection of User-Item of the Utility matrix.\n",
    "\n",
    "* Define a function to normalize the data.\n",
    "\n",
    "* Define a function to plot the ROC curves.\n",
    "\n",
    "* Use the above functions and evaluate the algorithm's performance. The following metrics will be used to compare the algorithm's performance for various parameters of the algorithm:\n",
    "    * RMSE (of both the test and training data)\n",
    "    * Run time \n",
    "    * AUC (Area Under the Curve) in ROC\n",
    "\n",
    "\n",
    "### Selecting the users randomly\n",
    "\n",
    "To test the scalability of our algorithm, we must select different amounts of training data, so that the algorithm's performance can be compared by recording the runtimes for different volumes of training data. To achieve this requirement, let us define a python function that randomly selects the data belonging to a given number of users. \n",
    "\n",
    "**NOTE:**\n",
    "We will NOT use the following function (of selecting the users randomly) in this project, since we will use the complete data to train and test our algorithm. However, I included this algorithm so that we have a complete frame work to develop and test SGD algorithm with various volumes of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_data(user_df, n=10,seed=1234):\n",
    "    #Selecting only n users randomly\n",
    "    #Set the seed, to seed to reproduce the same results\n",
    "    np.random.seed(seed)\n",
    "    uids = np.random.randint(1,user_df[\"user_id\"].max(),n)\n",
    "\n",
    "    user_df=user_df.iloc[uids]\n",
    "    uids = [i+1 for i in uids]\n",
    "\n",
    "    #Combined data frame\n",
    "    df = pd.merge(pd.merge(user_df,ratings_df),movie_df)\n",
    "    #print \"All columns combined (sample records):\"\n",
    "    #display(df.head())\n",
    "\n",
    "    return [df, user_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building utility matrix\n",
    "The following function will build the utility matrix. If a user has rated the same joke more than once, then we will take the average of such ratings to represent the user rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_utility_matrix(df):\n",
    "        \n",
    "        ##Confine the columns to just user ID, Item ID, and rating only\n",
    "        df_final = df[[\"user_id\",\"item_id\",\"rating\"]]\n",
    "\n",
    "        #Some users have rated the same movie multiple times. So taking mean of such ratings\n",
    "        df_final = df_final.groupby([\"user_id\",\"item_id\"]).mean()\n",
    "        df_final = df_final.reset_index()\n",
    "\n",
    "        #Building the utility matrix\n",
    "        Utility = df_final.pivot(index=\"user_id\",columns=\"item_id\",values=\"rating\")\n",
    "        Utility.columns.names=[\" \"]\n",
    "        return Utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into test and train data sets\n",
    "We will create a function that takes Utility matrix as input, along with the test data's size (expressed in percentage), and returns test and training data as output.\n",
    "\n",
    "The function will first identify the cells in the utility matrix where a joke has been rated by at least 2 users, and randomly pick the desired percentage of such cells as test data. This way we can eliminate the chance of picking any joke rated by single user as test data. So, unless a joke has at least 2 ratings, we will not consider that joke to test our algorithm's performance.\n",
    "\n",
    "NOTE: In these functions, we assume that the rows of Utility matrix represent the user IDs and the columns represent the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define a function that gets the ratings values at the \n",
    "#intersection of row_idx and col_idx values, where\n",
    "#row_idx and col_idx are lists\n",
    "\n",
    "def get_ratings(Utility,row_idx,col_idx,indices=True):\n",
    "    '''\n",
    "       row_idx and col_idx are lists containing the indices of the utility matrix.\n",
    "       If indices=True, then the row_idx and col_idx represent the actual index value and column name\n",
    "       else, they represent the row number and column number respectively. \n",
    "        \n",
    "    '''\n",
    "    ratings = list()\n",
    "     \n",
    "    if len(row_idx) == len(col_idx):\n",
    "        if indices:\n",
    "            for i in xrange(len(col_idx)):\n",
    "                ratings.append(Utility.loc[row_idx[i],col_idx[i]])\n",
    "        else:\n",
    "            for i in xrange(len(col_idx)):\n",
    "                ratings.append(Utility.iloc[row_idx[i],col_idx[i]])\n",
    "        return ratings\n",
    "    else:\n",
    "        print \"Error. The lengths of the row and col locations must be same\"\n",
    "\n",
    "\n",
    "def split_data(Utility,test_perc=20):\n",
    "        #What number makes the 20% of the ratings?\n",
    "        #Find the cell locations where there is a true rating.\n",
    "        rows,cols=np.where(~np.isnan(Utility))\n",
    "\n",
    "        #What percentage of cells have the true rating?\n",
    "        nan_perc = 100-100*float(len(cols))/(Utility.shape[0]*Utility.shape[1])\n",
    "        non_nan_perc = 100*float(len(cols))/(Utility.shape[0]*Utility.shape[1])\n",
    "        \n",
    "        #Find the number of observations needed for the test data\n",
    "        test_number = np.trunc(test_perc / 100.0 * len(cols))\n",
    "        \n",
    "        #Find the locations (row,col) in the Utility matrix\n",
    "        #wherever we have a genuine value. The ratings_locations data frame (defined below)\n",
    "        #will have these (row-column) details.\n",
    "        ratings_locations = pd.DataFrame(zip(rows,cols),columns = [\"row\",\"column\"])\n",
    "\n",
    "        #Get the column locations which have at least 2 ratings.\n",
    "        #This will make sure that we do not accidentally select a \n",
    "        #rating (which is the only rating available for the item or row) \n",
    "        ratings_counts = ratings_locations.groupby([\"column\"])['row'].count()\n",
    "        #print ratings_counts\n",
    "        \n",
    "        #display(ratings_counts)\n",
    "        cols_num_2_ratings = list(ratings_counts[ratings_counts>1].index)\n",
    "        test_row_num = list()\n",
    "        test_col_num = list()\n",
    "\n",
    "        sample_count = 0\n",
    "        \n",
    "        train_df = Utility.copy()\n",
    "        for i in cols_num_2_ratings:\n",
    "            #The random choice is important. It helps us to randomly \n",
    "            #select the row location so that we do not select the value from the \n",
    "            #same row location.\n",
    "            \n",
    "            #Get the location of the row and columns into variables\n",
    "            temp_test_row = np.random.choice(np.where(~np.isnan(Utility.iloc[:,i]))[0])\n",
    "            temp_test_col = i\n",
    "            \n",
    "            #Keep a track of the sample size\n",
    "            sample_count = sample_count + 1\n",
    "            \n",
    "            #If a user-item pair is selected for test, make that value as NA in training data \n",
    "            #However, there is a chance that the whole row could be NA, after this operation,\n",
    "            #since a column might be already selected and made as NA.\n",
    "            #So save the current value in tem_value, and \n",
    "            #re-assign to the same row-column value in train_df, if the operation\n",
    "            #results in the whole row filled with NA.\n",
    "            temp_value=train_df.iloc[temp_test_row,temp_test_col]\n",
    "            train_df.iloc[temp_test_row,temp_test_col] = np.nan\n",
    "            ##Undo the change in training data, if the change results in all NAs in the row\n",
    "            if np.isnan(train_df.iloc[temp_test_row,:]).all():\n",
    "                sample_count = sample_count - 1\n",
    "                train_df.iloc[temp_test_row,temp_test_col] = temp_value\n",
    "                continue\n",
    "            test_row_num.append(temp_test_row)\n",
    "            test_col_num.append(temp_test_col)\n",
    "            \n",
    "            #Stop data selection once we obtain the desired number of samples\n",
    "            if sample_count >= test_number:\n",
    "                break\n",
    "            \n",
    "        \n",
    "        ##Get the ratings at the intersection of row and column numbers from the \n",
    "        ##Utility matrix\n",
    "        test_ratings=get_ratings(Utility,test_row_num,test_col_num,indices=False)\n",
    "\n",
    "        ##Prepare the test data frame\n",
    "        user_id = [Utility.index[i] for i in test_row_num]\n",
    "        item_id = [Utility.columns[i] for i in test_col_num]\n",
    "\n",
    "        test_df = pd.DataFrame(zip(test_row_num,test_col_num,\n",
    "                           user_id,\n",
    "                           item_id,\n",
    "                           test_ratings),columns=[\"row_number\",\"column_number\",\"user_id\",\"item_id\",\"rating\"])\n",
    "        \n",
    "        return [train_df,test_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the Utility matrix\n",
    "\n",
    "We will define a function _normalize(M)_ that performs the normalization of Utility matrix _M_ based on the following logic. Normalization helps us to eliminate user and item biases.\n",
    "\n",
    "*normalize(M):* This function takes numpy matrix M as input and normalizes the matrix's data using the following logic:\n",
    "1. For each row, get the respective mean (ignoring the NANs).\n",
    "2. Subtract the means obtained in step-1 from the respective rows\n",
    "3. Get the means of the columns of the modified matrix from step-2\n",
    "4. Subtract the column means from the respective columns of the modified matrix, obtained in step-2\n",
    "\n",
    "**NOTE:**\n",
    "The following block implements the normalization in Python. But we also used the same normalization technique in PySpark also. Refer to *Appendix-B* for the implementation of normalization using PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Normalize the Utility matrix:\n",
    "##Subtract the avg user rating and avg item rating from the item in M\n",
    "#print M\n",
    "def list_mean(l):\n",
    "    if np.isnan(l).all():\n",
    "        print \"list_mean() message: All NA values. Check the logic.\"\n",
    "    return np.nanmean(l)\n",
    "\n",
    "def normalize(M):\n",
    "    #Convert M to a numpy array\n",
    "    #print \"In normalize\"\n",
    "    M = np.array(M)\n",
    "    \n",
    "    #Get the column means (or items mean)\n",
    "    items_mean=np.apply_along_axis(list_mean,0,M)\n",
    "    \n",
    "    #If an item is NOT rated by any user, then we will get NA for mean\n",
    "    #So for such instances\n",
    "    if np.isnan(np.sum(items_mean)):\n",
    "        print \"WARNING: Items has NAN values. which is incorrect\"\n",
    "\n",
    "    #Subtract the columns mean from the respective columns\n",
    "    M_normalized = M[:,] - items_mean\n",
    "    \n",
    "    #Get the rows means (or users mean) using the partially normalized matrix\n",
    "    users_mean = np.apply_along_axis(list_mean,1,M)\n",
    "    if np.isnan(np.sum(users_mean)):\n",
    "        print \"WARNING: Users has NAN values. which is incorrect\"\n",
    "\n",
    "    #Subtract the rows means\n",
    "    M_normalized = (M_normalized[:,].T- users_mean)\n",
    "    \n",
    "    #Transform back and return\n",
    "    return [M_normalized.T, items_mean, users_mean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The work-flow and the role of various functions defined for the computation of U and V factors, based on SGD method is shown below:\n",
    "\n",
    "### Figure 2: SGD based recommender work-flow\n",
    "<img src=\"process-2.png\">\n",
    "\n",
    "**Steps**\n",
    "1. The pandas data frame \"Ratings data\" (with columns: user_id, item_id, rating) is supplied as input to *build_utility_matrix()* function. The input data frame MUST have only 3 columns with the names: user_id, item_id, rating representing the user ID, item ID and rating respectively. The user ID and item ID clumns must be integers, and the rating column can be a any real number.\n",
    "2. *build_utility_matrix()* produces *Utility Matrix* as output\n",
    "3. *Utility Matrix* is supplied as input to *split_data()*, and *split_data()* produces two data frames: Test and training, In this process, split_data() utilizes the function *get_ratings()*, which gets the rating from the utility matrix based on the column and row indices or column and row numbers. The splitting of the data happens randomly\n",
    "4. The training data frame is supplied as input to *normalize()* function. The *normalize()* function utilizes *list_mean()*, which computes the mean of the input list ignoring the NA values \n",
    "5. The *normalize()* function produces a normalized data frame using the training data\n",
    "6. The normalized data frame is supplied as input to *SGD_factorization()* function. The *SGD_function()* will make use of the functions *SGD_compute_U_row()*, *SGD_compute_V_col()* and *get_RMSE()*. The *SGD_compute_U_row()* will adjust the values of the U matrix's row, the *SGD_compute_V_col()* will adjust the V matrix's column, and the *get_RMSE()* will be used to compute the Root Mean Squared error (RMSE) between the normalized matrix and UV matrix product. Since the normalized input matrix is sparse, only the available elements in the input matrix will be used to compute the RMSE\n",
    "7. The *SGD_factorization()* will produce U and V factors, which are optimized based on the SGD algorithm\n",
    "8. The U and V matrices are multiplied to get the UV matrix. This UV matrix will have the same dimensions as the Utility matrix, but the UV matrix will have al the elements unlike the Utility matrix (which is a sparse matrix).\n",
    "9. The test data, UV matrix are used to compute the test RMSE error\n",
    "\n",
    "In the next section, we will show how these steps are combined to obtain the optimal parameters for the SGD algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning SGD algorithm's parameters\n",
    "\n",
    "For SGD algorithm, we have the following parameters to tune:\n",
    "\n",
    "* $\\lambda_1$: The regularization parameter while finding U matrix\n",
    "* $\\lambda_2$: The regularization parameter while finding V matrix\n",
    "* $d$: Desired number of latent factors\n",
    "* $n$: Number of users to select. This indirectly controls the volume of the training data\n",
    "\n",
    "* In our evaluation, we will use the same values for $\\lambda_1$ and $\\lambda_2$. We will use the following values for these parameters:\n",
    "\n",
    "$$\\lambda_{1,2} = [0.1,1,2,3,4,5,10,100]$$\n",
    "\n",
    "* We will select $n$ as $59132$. We have a maximum of 59132 users in the data set\n",
    "\n",
    "* Out of the _n_ users ratings, 80% of data will be used for training and 20% for testing. The training data and test data are randomly selected\n",
    "\n",
    "* The value of $d$ (latent factors) will have the following values:\n",
    "$$d=[2,5,10,15,20,25,30,35,40,50,60,80,100]$$\n",
    "\n",
    "* We will use a constant learning rate of 0.00001\n",
    "\n",
    "* For each parameter combination, we will get the test and training error\n",
    "\n",
    "* The experiment is repeated 5 times. For each iteration, we select 80% of the data for training and 20% of the data for testing\n",
    "\n",
    "* The average of test and training errors for all the parameters combinations in all the iterations are obtained. The least average test error is finally picked as the optimal set of parameters to implement the SGD algorithm for the Jokes data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "Do NOT execute the following code, since this code will run for a while. It ran for 1 hour on a computer with 16GB RAM. To save time, I saved the performance metrics of various parameters combinations in a file named \"performance_df.csv\". This file can be downloaded from the Github location: https://goo.gl/mEE6G6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training episode: 1\n",
      "Training episode: 2\n",
      "Training episode: 3\n",
      "Training episode: 4\n",
      "Training episode: 5\n"
     ]
    }
   ],
   "source": [
    "#Rename the ratings_df columns, since the build_utility() function requires these column names: \n",
    "#[\"user_id\",\"item_id\",\"rating\"]\n",
    "\n",
    "ratings_df.columns = [\"user_id\",\"item_id\",\"rating\"]\n",
    "\n",
    "#Initialize the lambda1 values\n",
    "#The same values will be used for lambda2 also\n",
    "lambda1 = [0.1,1,2,3,4,5,10,20,30,40,100]\n",
    "\n",
    "#Select the ratings data based on the \n",
    "#following number of users\n",
    "total_users = [59132]\n",
    "\n",
    "#lambda1 = [1,2]\n",
    "#total_users = [20,30]\n",
    "\n",
    "#Learning rate for SGD\n",
    "alpha = 0.00001\n",
    "#alpha = [0.01, 0.001, 0.0001, 0.00001, 0.0000001,0.000000001]\n",
    "\n",
    "#Error tolerance\n",
    "#Maximum error acceptable to terminate the iterations\n",
    "error_diff = 0.0000000001\n",
    "\n",
    "#Seed to reproduce the results\n",
    "seed = 10\n",
    "\n",
    "#Place holders for metrics\n",
    "reg = []\n",
    "num_of_users = []\n",
    "latent_factors = []\n",
    "train_error = []\n",
    "test_error = []\n",
    "run_time = []\n",
    "algorithm = []\n",
    "iterations = []\n",
    "LR = []\n",
    "#Maximum number of iterations\n",
    "n = 1000\n",
    "from time import time\n",
    "\n",
    "df = ratings_df.copy()\n",
    "Utility = build_utility_matrix(df)\n",
    "train_df,test_df=split_data(Utility,test_perc=20)\n",
    "epoch = list()\n",
    "for episode in [1,2,3,4,5]:\n",
    "    print \"Training episode: {}\".format(episode)\n",
    "    train_normalized,train_items_mean,train_users_mean = normalize(train_df)\n",
    "    train_users=train_df.shape[0]\n",
    "    for a in lambda1:\n",
    "        #print \"evaluating lambda={} iteration\".format(a)\n",
    "        c = [2,5,10,15,20,25,30,35,40,50,60,80,100]\n",
    "        for d in c:\n",
    "            #Running SGD for the given parameters combination\n",
    "            #for rate in alpha:\n",
    "                #LR.append(rate)\n",
    "                algorithm.append(\"SGD\")\n",
    "                reg.append(a)\n",
    "                num_of_users.append(b)\n",
    "                latent_factors.append(d)\n",
    "                start = time() # Get start time\n",
    "                U, V, error = SGD_factorization(np.array(train_normalized),d, a, a, n, error_diff, seed,alpha)\n",
    "                end = time() # Get start time\n",
    "                train_error.append(error[-1])\n",
    "                iterations.append(len(error))\n",
    "                run_time.append(end-start)\n",
    "\n",
    "                temp_UV = np.dot(U,V) + train_items_mean\n",
    "                temp_UV = temp_UV.T + train_users_mean\n",
    "                temp_UV = temp_UV.T\n",
    "                predicted_ratings = get_ratings(pd.DataFrame(temp_UV),list(test_df[\"row_number\"]),\n",
    "                                                   list(test_df[\"column_number\"]),indices=False)\n",
    "                test_error.append(np.sqrt((np.nanmean(np.square(\n",
    "                                    np.array(test_df[\"rating\"]) - np.array(predicted_ratings))))))\n",
    "                epoch.append(episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance metrics obtained for various parameters combinations (for all the 5 training episodes) are written to a file, so that we do not have to re-execute the above code block again. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average performance metrics obtained for various parameters combinations.\n",
      "\n",
      "The metrics are sorted in the increasing order of average TEST error\n",
      "\n",
      "Displaying the top rows only.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Reg</th>\n",
       "      <th>Latent_Factors</th>\n",
       "      <th>Avg_Run_Time</th>\n",
       "      <th>Avg_Training_Error</th>\n",
       "      <th>Avg_Test_Error</th>\n",
       "      <th>Avg_Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SGD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>3.2880</td>\n",
       "      <td>1.890782</td>\n",
       "      <td>3.695142</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>SGD</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60</td>\n",
       "      <td>6.5704</td>\n",
       "      <td>1.890789</td>\n",
       "      <td>3.695788</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>SGD</td>\n",
       "      <td>40.0</td>\n",
       "      <td>60</td>\n",
       "      <td>4.5240</td>\n",
       "      <td>1.890779</td>\n",
       "      <td>3.695791</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>SGD</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60</td>\n",
       "      <td>4.4480</td>\n",
       "      <td>1.890782</td>\n",
       "      <td>3.695791</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>SGD</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60</td>\n",
       "      <td>6.2584</td>\n",
       "      <td>1.890778</td>\n",
       "      <td>3.695793</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SGD</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60</td>\n",
       "      <td>4.4800</td>\n",
       "      <td>1.890769</td>\n",
       "      <td>3.695793</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SGD</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>4.6008</td>\n",
       "      <td>1.890782</td>\n",
       "      <td>3.695793</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.1</td>\n",
       "      <td>60</td>\n",
       "      <td>3.0220</td>\n",
       "      <td>1.890780</td>\n",
       "      <td>3.695793</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>SGD</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60</td>\n",
       "      <td>4.6580</td>\n",
       "      <td>1.890803</td>\n",
       "      <td>3.695793</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SGD</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60</td>\n",
       "      <td>3.1560</td>\n",
       "      <td>1.890777</td>\n",
       "      <td>3.695793</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Algorithm    Reg  Latent_Factors  Avg_Run_Time  Avg_Training_Error  \\\n",
       "23        SGD    1.0              60        3.2880            1.890782   \n",
       "140       SGD  100.0              60        6.5704            1.890789   \n",
       "127       SGD   40.0              60        4.5240            1.890779   \n",
       "114       SGD   30.0              60        4.4480            1.890782   \n",
       "101       SGD   20.0              60        6.2584            1.890778   \n",
       "49        SGD    3.0              60        4.4800            1.890769   \n",
       "36        SGD    2.0              60        4.6008            1.890782   \n",
       "10        SGD    0.1              60        3.0220            1.890780   \n",
       "75        SGD    5.0              60        4.6580            1.890803   \n",
       "62        SGD    4.0              60        3.1560            1.890777   \n",
       "\n",
       "     Avg_Test_Error  Avg_Iterations  \n",
       "23         3.695142             7.0  \n",
       "140        3.695788            23.0  \n",
       "127        3.695791            13.2  \n",
       "114        3.695791            12.6  \n",
       "101        3.695793            21.2  \n",
       "49         3.695793            13.0  \n",
       "36         3.695793            13.4  \n",
       "10         3.695793             5.8  \n",
       "75         3.695793            13.2  \n",
       "62         3.695793             6.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the performance metrics sorted in the increasing order of TRAINING error:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Reg</th>\n",
       "      <th>Latent_Factors</th>\n",
       "      <th>Avg_Run_Time</th>\n",
       "      <th>Avg_Training_Error</th>\n",
       "      <th>Avg_Test_Error</th>\n",
       "      <th>Avg_Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>SGD</td>\n",
       "      <td>40.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2.9224</td>\n",
       "      <td>1.009886</td>\n",
       "      <td>3.739950</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>SGD</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2.9700</td>\n",
       "      <td>1.009887</td>\n",
       "      <td>3.739955</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SGD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2.2340</td>\n",
       "      <td>1.009889</td>\n",
       "      <td>3.739955</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>SGD</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3.5940</td>\n",
       "      <td>1.009889</td>\n",
       "      <td>3.739955</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>SGD</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3.8440</td>\n",
       "      <td>1.009889</td>\n",
       "      <td>3.739955</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Algorithm   Reg  Latent_Factors  Avg_Run_Time  Avg_Training_Error  \\\n",
       "129       SGD  40.0             100        2.9224            1.009886   \n",
       "64        SGD   4.0             100        2.9700            1.009887   \n",
       "25        SGD   1.0             100        2.2340            1.009889   \n",
       "77        SGD   5.0             100        3.5940            1.009889   \n",
       "51        SGD   3.0             100        3.8440            1.009889   \n",
       "\n",
       "     Avg_Test_Error  Avg_Iterations  \n",
       "129        3.739950             6.4  \n",
       "64         3.739955             6.2  \n",
       "25         3.739955             3.4  \n",
       "77         3.739955             9.6  \n",
       "51         3.739955            10.4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance_df = pd.DataFrame(zip(algorithm,reg,num_of_users,latent_factors,run_time,\n",
    "#                                  train_error,test_error,iterations,epoch),\n",
    "#                             columns=['algorithm','reg','num_of_users','latent_factors',\n",
    "#                                      'run_time','train_error','test_error','iterations','epoch'])\n",
    "\n",
    "##Writing the performance metrics to a file, so that we do not have to\n",
    "##run the above block again\n",
    "#performance_df.to_csv(\"performance_df.csv\")\n",
    "performance_df = pd.read_csv(\"performance_df.csv\")\n",
    "#display(performance_df.sort([\"test_error\"]))\n",
    "\n",
    "display_df = performance_df.groupby(['algorithm',\n",
    "                                     'reg','num_of_users',\n",
    "                                     'latent_factors']).mean().reset_index().sort(\"test_error\")[['algorithm',\n",
    "                                                                                                 'reg',\n",
    "                                                                                                 \n",
    "                                                                                                 'latent_factors',\n",
    "                                      'run_time','train_error','test_error','iterations']]\n",
    "display_df.columns = [\"Algorithm\",\"Reg\",\"Latent_Factors\",\"Avg_Run_Time\",\n",
    "                      \"Avg_Training_Error\",\"Avg_Test_Error\",\"Avg_Iterations\"]\n",
    "print \"Average performance metrics obtained for various parameters combinations.\"\n",
    "print \"\\nThe metrics are sorted in the increasing order of average TEST error\"\n",
    "print \"\\nDisplaying the top rows only.\"\n",
    "display(display_df.head(10))\n",
    "\n",
    "\n",
    "print \"Displaying the performance metrics sorted in the increasing order of TRAINING error:\"\n",
    "display(display_df.sort([\"Avg_Training_Error\"]).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above display, we can infer the following:\n",
    "* The optimal number of latent factors is 60, since the average test error is the least for 60 latent factors.\n",
    "* The Regularization (Reg) parameter has no effect on the average test error, since the test error almost the same for all the regularization parameters, and with 60 latent factors.\n",
    "* The average training error for 100 latent factors is minimum, but the average test error is not the minimum for 100 latent factors. This suggests that overfitting is happening at 100 latent factors\n",
    "\n",
    "Since Reg value has no significant effect on the test error, we will choose the following parameters combination as the optimal combination:\n",
    "\n",
    "$$Reg = 1, \\mbox{Latent Factors} = 60, \\mbox{Learning rate} =  0.00001$$\n",
    "\n",
    "Note that we did NOT vary the learning rate while gathering the performance metrics. Just to make sure *how* the learning rate effects the test error, the following code block will use the [0.01, 0.001, 0.0001, 0.00001, 0.0000001,0.000000001] values as the learning rate, along the with the above parameter values, and computes the test error for each learning rate.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LR = 0.01\n",
      "Evaluating LR = 0.001\n",
      "Evaluating LR = 0.0001\n",
      "Evaluating LR = 1e-05\n",
      "Evaluating LR = 1e-07\n",
      "Evaluating LR = 1e-09\n",
      "Test Error for various learning rates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Test Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>7843.162685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>4.231813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>4.231626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>4.231626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>4.231626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>4.231626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate   Test Error\n",
       "0   1.000000e-02  7843.162685\n",
       "1   1.000000e-03     4.231813\n",
       "2   1.000000e-04     4.231626\n",
       "3   1.000000e-05     4.231626\n",
       "4   1.000000e-07     4.231626\n",
       "5   1.000000e-09     4.231626"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_error_1 = list()\n",
    "test_error_1 = list()\n",
    "iterations_1 = list()\n",
    "ratings_df.columns = [\"user_id\",\"item_id\",\"rating\"]\n",
    "df = ratings_df.copy()\n",
    "Utility = build_utility_matrix(df)\n",
    "train_df,test_df=split_data(Utility,test_perc=20)\n",
    "#train_users_1=train_df.shape[0]\n",
    "train_normalized,train_items_mean,train_users_mean = normalize(train_df)\n",
    "\n",
    "#print train_users\n",
    "\n",
    "#SGD_factorization(np.array(train_normalized),d, a, a, n, error_diff, seed,alpha)\n",
    "alpha_1 = [0.01, 0.001, 0.0001, 0.00001, 0.0000001,0.000000001]\n",
    "\n",
    "for rate in alpha_1:\n",
    "    print \"Evaluating LR = {}\".format(rate)\n",
    "    U, V, error = SGD_factorization(np.array(train_normalized),60, 1, 1, 1000, 0.0000000001, 10,rate)\n",
    "    #print error[-1]\n",
    "\n",
    "    train_error_1.append(error[-1])\n",
    "    iterations_1.append(len(error))\n",
    "    temp_UV = np.dot(U,V) + train_items_mean\n",
    "    temp_UV = temp_UV.T + train_users_mean\n",
    "    temp_UV = temp_UV.T\n",
    "\n",
    "\n",
    "    predicted_ratings = get_ratings(pd.DataFrame(temp_UV),list(test_df[\"row_number\"]),\n",
    "                                                   list(test_df[\"column_number\"]),indices=False)\n",
    "    test_error_1.append(np.sqrt(np.nanmean(np.square(np.array(test_df[\"rating\"]) - np.array(predicted_ratings)))))\n",
    "\n",
    "print \"Test Error for various learning rates:\"\n",
    "pd.DataFrame(zip(alpha_1,test_error_1),columns = [\"Learning Rate\", \"Test Error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate of 0.01 is not optimal. But any other learning rate listed in the above display is optimal, although we stick to the learning rate value of 0.00001, which was used to evaluate the algorithm's performance for various parameters combinations. Also we will select the learning rate which is not too slow (since the convergence will take a long time) or too fast, since the overshooting may occur. In the above display, we obtained a huge test error of 7843, because of overshooting in the gradient descent algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the best model and evaluating the ROC Area\n",
    "\n",
    "We will use the following parameters to train the SGD model and plot the ROC (Receiver Operating Characteristic) curves to identify if the SGD model's performance is acceptable. These are the parameters which were identified based on the average test error in 5 different runs of the SGD algorithm using different sets (randomly selected) of training data.\n",
    "\n",
    "$$Reg = 1$$\n",
    "\n",
    "$$\\mbox{Latent Factors} = 60$$\n",
    "\n",
    "$$\\mbox{Learning rate} =  0.00001$$\n",
    "\n",
    "If the AUC (Area Under the ROC Curve) is less than or equal to 0.5, then our model is not a good model and our model is no better than just random guessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train the model with the optimal parameter combinations identified\n",
    "train_df,test_df=split_data(Utility,test_perc=20)\n",
    "train_normalized,train_items_mean,train_users_mean = normalize(train_df)\n",
    "\n",
    "\n",
    "U, V, error = SGD_factorization(np.array(train_normalized),60, 1, 1, 1000, 0.0000000001, 10,0.00001)\n",
    "#In the above call, we used 60 latent factors, regularization parms as 1, 1\n",
    "#0.0000000001 is the error tolerance (stop the iteration if the consecutive errors difference is less than\n",
    "# or equal to 0.0000000001)\n",
    "#Learning rate is 0.00001\n",
    "\n",
    "pred = np.dot(U,V) + train_items_mean\n",
    "pred = pred.T + train_users_mean\n",
    "pred = pred.T\n",
    "# pred will have the same shape as the utility matrix. \n",
    "# But pred matrix will have an estimate of the missing entries in the Utility matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the test data predictions SGD\n",
    "The following code will get the predicted ratings for the test data using SGD method. Whenever our model predicts a rating of more than 10 or less than -10, we change that rating to 10 and -10 respectively. Also we will normalize the predicted ratings using the following formula:\n",
    "\n",
    "$$x_{new} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$\n",
    "\n",
    "Since our ratings always belong to $[-10,10]$, we can re-write the above formula as:\n",
    "\n",
    "$$x_{new} = \\frac{x - (-10)}{10 - (-10)} = \\frac{x +10}{20}$$\n",
    "\n",
    "The main advantage of this scaling is that all the new ratings will have a value between $[0,1]$. These new values can be interpreted as the probability that a user likes the movie, and this interpretation will help us to plot the ROC curve for our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the predicted ratings for the test data\n",
    "SGD_predicted_ratings = get_ratings(pd.DataFrame(pred),list(test_df[\"row_number\"]),\n",
    "                                               list(test_df[\"column_number\"]),indices=False)\n",
    "\n",
    "SGD_predicted_ratings = np.array(SGD_predicted_ratings)\n",
    "\n",
    "#If any predicted rating is more than 10, then make that rating as 10\n",
    "SGD_predicted_ratings[SGD_predicted_ratings > 10] = 10\n",
    "\n",
    "#If any predicted rating is less than -10, then make that rating as -10\n",
    "SGD_predicted_ratings[SGD_predicted_ratings < -10] = -10\n",
    "\n",
    "#Normalize the rating to [0,1] interval\n",
    "SGD_predicted_prob = (SGD_predicted_ratings+10)/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the predicted ratings and probabilities to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_number</th>\n",
       "      <th>column_number</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>SGD_predicted_ratings</th>\n",
       "      <th>SGD_predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.656</td>\n",
       "      <td>-6.728410</td>\n",
       "      <td>0.163579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39437</td>\n",
       "      <td>1</td>\n",
       "      <td>42402</td>\n",
       "      <td>7</td>\n",
       "      <td>-6.938</td>\n",
       "      <td>-7.884690</td>\n",
       "      <td>0.105765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2106</td>\n",
       "      <td>2</td>\n",
       "      <td>2281</td>\n",
       "      <td>8</td>\n",
       "      <td>-5.594</td>\n",
       "      <td>1.388690</td>\n",
       "      <td>0.569434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40590</td>\n",
       "      <td>3</td>\n",
       "      <td>43612</td>\n",
       "      <td>13</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.638931</td>\n",
       "      <td>0.468053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42453</td>\n",
       "      <td>4</td>\n",
       "      <td>45579</td>\n",
       "      <td>15</td>\n",
       "      <td>-6.656</td>\n",
       "      <td>0.787004</td>\n",
       "      <td>0.539350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_number  column_number  user_id  item_id  rating  SGD_predicted_ratings  \\\n",
       "0          48              0       55        5  -6.656              -6.728410   \n",
       "1       39437              1    42402        7  -6.938              -7.884690   \n",
       "2        2106              2     2281        8  -5.594               1.388690   \n",
       "3       40590              3    43612       13   0.188              -0.638931   \n",
       "4       42453              4    45579       15  -6.656               0.787004   \n",
       "\n",
       "   SGD_predicted_prob  \n",
       "0            0.163579  \n",
       "1            0.105765  \n",
       "2            0.569434  \n",
       "3            0.468053  \n",
       "4            0.539350  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Add the predicted ratings and probabilities (normalized ratings) to the test data frame\n",
    "test_df[\"SGD_predicted_ratings\"] = SGD_predicted_ratings\n",
    "test_df[\"SGD_predicted_prob\"] = SGD_predicted_prob\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the ratings prediction problem as a binary classification (like/dislike) problem, we assume that a user likes a joke, if he gives a rating of more than 5, and dislikes the joke, if he rates the joke less than or equal to 5. Based on this assumption, we will add a new column \"actually_liked\" to the test data. This column will have a 1 if the user has given more than 5 rating to a joke, else this column will have 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diplaying a set of initial rows from the test data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_number</th>\n",
       "      <th>column_number</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>SGD_predicted_ratings</th>\n",
       "      <th>SGD_predicted_prob</th>\n",
       "      <th>actually_liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.656</td>\n",
       "      <td>-6.728410</td>\n",
       "      <td>0.163579</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39437</td>\n",
       "      <td>1</td>\n",
       "      <td>42402</td>\n",
       "      <td>7</td>\n",
       "      <td>-6.938</td>\n",
       "      <td>-7.884690</td>\n",
       "      <td>0.105765</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2106</td>\n",
       "      <td>2</td>\n",
       "      <td>2281</td>\n",
       "      <td>8</td>\n",
       "      <td>-5.594</td>\n",
       "      <td>1.388690</td>\n",
       "      <td>0.569434</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40590</td>\n",
       "      <td>3</td>\n",
       "      <td>43612</td>\n",
       "      <td>13</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-0.638931</td>\n",
       "      <td>0.468053</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42453</td>\n",
       "      <td>4</td>\n",
       "      <td>45579</td>\n",
       "      <td>15</td>\n",
       "      <td>-6.656</td>\n",
       "      <td>0.787004</td>\n",
       "      <td>0.539350</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_number  column_number  user_id  item_id  rating  SGD_predicted_ratings  \\\n",
       "0          48              0       55        5  -6.656              -6.728410   \n",
       "1       39437              1    42402        7  -6.938              -7.884690   \n",
       "2        2106              2     2281        8  -5.594               1.388690   \n",
       "3       40590              3    43612       13   0.188              -0.638931   \n",
       "4       42453              4    45579       15  -6.656               0.787004   \n",
       "\n",
       "   SGD_predicted_prob  actually_liked  \n",
       "0            0.163579             0.0  \n",
       "1            0.105765             0.0  \n",
       "2            0.569434             0.0  \n",
       "3            0.468053             0.0  \n",
       "4            0.539350             0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a copy of the rating\n",
    "actually_liked = test_df[\"rating\"].copy() \n",
    "\n",
    "#Encode the probability score as 0/1 to represent the prediction that the user really likes or dislikes \n",
    "#1 - if the user likes the joke\n",
    "#0 - if the user dislikes the joke\n",
    "actually_liked[actually_liked <= 5] = 0\n",
    "actually_liked[actually_liked > 5] = 1\n",
    "test_df[\"actually_liked\"]=actually_liked\n",
    "\n",
    "print \"Diplaying a set of initial rows from the test data:\"\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the ROC curve\n",
    "\n",
    "The following code will plot the ROC curve for our predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Area Under the Curve:0.907134502924\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGrCAYAAAB65GhQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKlIiIhKz/h/0kd7yDuPVnwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa9f3c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let us create a function to plot the ROC curves\n",
    "def plot_roc_curves(fpr,tpr,ax,models,colors=[\"red\",\"green\",\"darkorange\",\"green\",\"black\",\"magenta\",\"cyan\"]):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import auc\n",
    "    lw=2 #Line weight\n",
    "    for key in range(len(fpr)):\n",
    "        line1, = ax.plot(fpr[key], tpr[key], linewidth=2,color=colors[key],\n",
    "                 label=models[key]+' ROC (area = %0.2f)' % auc(fpr[key],tpr[key]))\n",
    "    line2,=ax.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    ax.legend(loc='lower right',fancybox=True, framealpha=0.5)\n",
    "    \n",
    "    ax.set_ylabel('True positive rate')\n",
    "    ax.set_xlabel('False positive rate')\n",
    "    ax.set_title('ROC Curve(s)')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "##Import the required packages\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Dictionary to collect the False Positive Rates at various probabilities thresholds\n",
    "fpr = dict()\n",
    "\n",
    "#Dictionary to collect the True Positive Rates at various probabilities thresholds\n",
    "tpr = dict()\n",
    "\n",
    "#Dictionary to collect the probability thresholds used to compute the TPR and FPR\n",
    "thresholds=dict()\n",
    "\n",
    "#Get the probabilities that the target class=1 \n",
    "SGD_clf_test_scores=np.array(test_df[\"SGD_predicted_prob\"])\n",
    "\n",
    "#Get the FPR, TPR, thresholds used for unoptimized classifier\n",
    "fpr[0], tpr[0], thresholds[0] = roc_curve(test_df[\"actually_liked\"], y_score=SGD_clf_test_scores, pos_label=1)\n",
    "print \"SGD Area Under the Curve:\" + str(auc(fpr[0],tpr[0]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "#fig.suptitle('Categorical variables bar plots')\n",
    "models=[\"SGD\"]\n",
    "plot_roc_curves(fpr,tpr,ax,models)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the optimal threshold\n",
    "\n",
    "Using the test data, we obtained an AUC of 0.91, which is a very good score. We used a rating threshold of 5, to determine if a user will like a joke. But how do we know that this threshold is the optimal threshold? The AUC of 0.91 might have resulted due to pure randomness in the selection of test data, and it is not possible to confirm that 5 is the optimal threshold with just 1 instance of AUC score.\n",
    "\n",
    "We will find the ROC using various thresholds ranging from [4, 10] (in the increments of 0.1), for various random selections of the training data, and obtain the average ROC. We will select the threshold, for which the average ROC value is the maximum.\n",
    "\n",
    "The following code will compute the AUC for various thresholds for 5 times and obtains the average AUC for each threshold. This code will run for approximately 1 hour. So, in order to save the time, we saved the results of this code to a file called roc_analysis.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting episode: 1\n",
      "Completed episode: 1\n",
      "Processing time for episode: 1 is 480.348999977 seconds\n",
      "Starting episode: 2\n",
      "Completed episode: 2\n",
      "Processing time for episode: 2 is 496.98300004 seconds\n",
      "Starting episode: 3\n",
      "Completed episode: 3\n",
      "Processing time for episode: 3 is 494.321000099 seconds\n",
      "Starting episode: 4\n",
      "Completed episode: 4\n",
      "Processing time for episode: 4 is 495.914000034 seconds\n",
      "Starting episode: 5\n",
      "Completed episode: 5\n",
      "Processing time for episode: 5 is 506.942000151 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "threshold = np.arange(4,10.0,0.1)\n",
    "thres = []\n",
    "roc = []\n",
    "epoch = []\n",
    "ratings_df.columns = [\"user_id\",\"item_id\",\"rating\"]\n",
    "df = ratings_df.copy()\n",
    "Utility = build_utility_matrix(df)\n",
    "for episode in [1,2,3,4,5]:\n",
    "#for episode in [1]:\n",
    "    start = time()\n",
    "    print \"Starting episode: {}\".format(episode)\n",
    "    \n",
    "    for t in threshold:\n",
    "        train_df,test_df=split_data(Utility,test_perc=20)\n",
    "        train_normalized,train_items_mean,train_users_mean = normalize(train_df)\n",
    "\n",
    "        U, V, error = SGD_factorization(np.array(train_normalized),60, 1, 1, 1000, 0.0000000001, 10,0.00001)\n",
    "\n",
    "        pred = np.dot(U,V) + train_items_mean\n",
    "        pred = pred.T + train_users_mean\n",
    "        pred = pred.T\n",
    "        SGD_predicted_ratings = get_ratings(pd.DataFrame(pred),list(test_df[\"row_number\"]),\n",
    "                                            list(test_df[\"column_number\"]),indices=False)\n",
    "        if (np.isnan(SGD_predicted_ratings).any()):\n",
    "            print SGD_predicted_ratings\n",
    "            \n",
    "        SGD_predicted_ratings = np.array(SGD_predicted_ratings)\n",
    "        SGD_predicted_ratings[SGD_predicted_ratings > 10] = 10\n",
    "        SGD_predicted_ratings[SGD_predicted_ratings < -10] = -10\n",
    "        SGD_predicted_prob = (SGD_predicted_ratings+10)/20\n",
    "        test_df[\"SGD_predicted_ratings\"] = SGD_predicted_ratings\n",
    "        test_df[\"SGD_predicted_prob\"] = SGD_predicted_prob\n",
    "        actually_liked = test_df[\"rating\"].copy() \n",
    "        #print len(actually_liked[actually_liked > t]) \n",
    "        #print len(actually_liked[actually_liked <= t]) \n",
    "        if ((len(actually_liked[actually_liked > t]) == 0) | (len(actually_liked[actually_liked <= t]) == 0)):\n",
    "                 continue\n",
    "\n",
    "        actually_liked[actually_liked <= t] = 0\n",
    "        actually_liked[actually_liked > t] = 1\n",
    "        test_df[\"actually_liked\"]=actually_liked\n",
    "        #Dictionary to collect the False Positive Rates at various probabilities thresholds\n",
    "        fpr = dict()\n",
    "        #Dictionary to collect the True Positive Rates at various probabilities thresholds\n",
    "        tpr = dict()\n",
    "\n",
    "        #Dictionary to collect the probability thresholds used to compute the TPR and FPR\n",
    "        thresholds=dict()\n",
    "        SGD_clf_test_scores=np.array(test_df[\"SGD_predicted_prob\"])\n",
    "        if (np.isnan(SGD_clf_test_scores).any()):\n",
    "            print \"SGD_clf_test_scores contains NAN: {}\".format(SGD_clf_test_scores)\n",
    "            print test_df\n",
    "        #print \"passed\"\n",
    "        #if (np.isnan(SGD_clf_test_scores).any()):\n",
    "        #    continue\n",
    "        #if (numpy.isnan(test_df[\"actually_liked\"]).any()):\n",
    "        #    print \"SGD_clf_test_scores contains NAN: {}\".format(SGD_clf_test_scores)\n",
    "            \n",
    "        fpr[0], tpr[0], thresholds[0] = roc_curve(test_df[\"actually_liked\"], y_score=SGD_clf_test_scores, pos_label=1)\n",
    "        #print \"SGD Area Under the Curve:\" + str(auc(fpr[0],tpr[0]))\n",
    "\n",
    "        thres.append(t)\n",
    "        roc.append(auc(fpr[0],tpr[0]))\n",
    "        epoch.append(episode)\n",
    "    end = time()\n",
    "    print \"Completed episode: {}\".format(episode)\n",
    "    print \"Processing time for episode: {} is {} seconds\".format(episode,end-start)\n",
    "\n",
    "#Save the results to a file\n",
    "roc_analysis = pd.DataFrame(zip(thres, roc, epoch),columns=[\"threshold\",\"auc\",\"epoch\"])\n",
    "roc_analysis.to_csv(\"roc_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the initial rows of the average AUC, for various thresholds, sorted by AUC in descending order:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>9.9</td>\n",
       "      <td>0.952097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>9.6</td>\n",
       "      <td>0.888530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>9.4</td>\n",
       "      <td>0.885153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.873719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.868393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold       auc\n",
       "59        9.9  0.952097\n",
       "56        9.6  0.888530\n",
       "54        9.4  0.885153\n",
       "49        8.9  0.873719\n",
       "34        7.4  0.868393"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the file roc_analysis.csv, which was created in the above block\n",
    "roc_analysis = pd.read_csv(\"roc_analysis.csv\")\n",
    "roc_analysis = roc_analysis[[\"threshold\",\"auc\"]]\n",
    "display_df=roc_analysis.groupby([\"threshold\"]).mean().reset_index().sort([\"auc\"],ascending=False)\n",
    "print \"Displaying the initial rows of the average AUC, for various thresholds, sorted by AUC in descending order:\"\n",
    "display_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the average AUC values for different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FIGURE-3: Avg. AUC values for various thresholds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEZCAYAAACEkhK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xddecd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = display_df[\"threshold\"]\n",
    "y = display_df[\"auc\"]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#ax.fmt_ydata = millions\n",
    "plt.title(\"Avg AUC for various thresholds\")\n",
    "\n",
    "plt.plot((4, 10), (0.8, 0.8), '--',color=\"red\")\n",
    "plt.plot((4, 10), (0.85, 0.85), '--',color=\"red\")\n",
    "ax.set_xlabel(\"Threshold\")\n",
    "ax.set_ylabel(\"Avg AUC\")\n",
    "plt.plot(x, y, 'o')\n",
    "\n",
    "print \"\\nFIGURE-3: Avg. AUC values for various thresholds\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, we can infer the following:\n",
    "\n",
    "* For most of the thresholds, the average AUC values lie between 0.8 and 0.85. \n",
    "* As the threshold value increases, the variance of the average AUC values increases.\n",
    "* The highest AUC value obtained is 0.95, while the least AUC value obtained is 0.77, and both occurred for a threshold value of more than 9. \n",
    "* Most of the higher AUC values have occurred for a threshold of 7.5 or more.\n",
    "* For all the thresholds, the average AUC values are way above 0.5, and this suggests that our recommender is doing a better job than pure random guessing that a user likes an item.\n",
    "\n",
    "Even though most of the higher AUC values have occurred for a threshold of 7.5 or more, we do not want to use the 7.5 threshold, since we will end up setting the bar high, and the number of recommended items will be less. But setting the threshold to a value of 4, will qualify many items as the recommended items for a user, and may dilute the quality of the recommendations. So, let us choose the threshold value of 5 to determine if a user likes the item. If the predicted rating of an item for a user is more than 5, recommend the item to the user, else do not recommend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending jokes based on the predicted ratings by SGD method\n",
    "We will create a function, that takes the user_ID as input and returns the items recommended to the user ID. We will also provide the predicted ratings matrix as input, along with the ratings data frame (containing all the ratings), and the Utility matrix produced using the ratings data frame. The ratings data frame will help the function to get the list of items which were already rated by the user.\n",
    "\n",
    "Training the algorithm using the complete ratings data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_df,test_df=split_data(Utility,test_perc=20)\n",
    "Utility_normalized,Utility_items_mean,Utility_users_mean = normalize(Utility)\n",
    "U, V, error = SGD_factorization(np.array(Utility_normalized),60, 1, 1, 1000, 0.0000000001, 10,0.00001)\n",
    "pred = np.dot(U,V) + Utility_items_mean\n",
    "pred = pred.T + Utility_users_mean\n",
    "pred = pred.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will take a user ID as input and gives the list of recommended items as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user ID 129 has rated these jokes high (top 5 jokes):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4819</th>\n",
       "      <td>129</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4816</th>\n",
       "      <td>129</td>\n",
       "      <td>7</td>\n",
       "      <td>-4.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>129</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>129</td>\n",
       "      <td>13</td>\n",
       "      <td>-9.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>129</td>\n",
       "      <td>8</td>\n",
       "      <td>-9.719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  rating\n",
       "4819      129       15  -0.781\n",
       "4816      129        7  -4.906\n",
       "4815      129        5  -5.438\n",
       "4818      129       13  -9.562\n",
       "4817      129        8  -9.719"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Q. What's O. J. Simpson's web address? A. Slash, slash, backslash, slash, slash, escape.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>How many feminists does it take to screw in a light bulb? That's not funny.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Q. Did you hear about the dyslexic devil worshiper? A. He sold his soul to Santa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>They asked the Japanese visitor if they have elections in his country. \"Every morning,\" he answers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Q: What did the blind person say when given some matzah? A: Who the hell wrote this?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Joke-id  \\\n",
       "4         5   \n",
       "6         7   \n",
       "7         8   \n",
       "12       13   \n",
       "14       15   \n",
       "\n",
       "                                                                                                    Text  \n",
       "4               Q. What's O. J. Simpson's web address? A. Slash, slash, backslash, slash, slash, escape.  \n",
       "6                            How many feminists does it take to screw in a light bulb? That's not funny.  \n",
       "7                      Q. Did you hear about the dyslexic devil worshiper? A. He sold his soul to Santa.  \n",
       "12   They asked the Japanese visitor if they have elections in his country. \"Every morning,\" he answers.  \n",
       "14                  Q: What did the blind person say when given some matzah? A: Who the hell wrote this?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended items for the user ID: 129 are given below.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>An explorer in the deepest Amazon suddenly finds himself surrounded by a bloodthirsty group of natives. Upon surveying the situation, he says quietly to himself, \"Oh God, I'm screwed.\" The sky darkens and a voice booms out, \"No, you are NOT screwed. Pick up that stone at your feet and bash in the head of the chief standing in front of you.\" So with the stone he bashes the life out of the chief. He stands above the lifeless body, breathing heavily and looking at 100 angry natives... The voice booms out again, \"Okay....NOW you're screwed.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>One Sunday morning William burst into the living room and said, \"Dad! Mom! I have some great news for you! I am getting married to the most beautiful girl in town. She lives a block away and her name is Susan.\" After dinner, William's dad took him aside. \"Son, I have to talk with you. Your mother and I have been married 30 years. She's a wonderful wife but she has never offered much excitement in the bedroom, so I used to fool around with women a lot. Susan is actually your half-sister, and I'm afraid you can't marry her.\" William was heart-broken. After eight months he eventually started dating girls again. A year later he came home and very proudly announced, \"Dianne said yes! We're getting married in June.\" Again his father insisted on another private conversation and broke the sad news. \"Dianne is your half-sister too, William. I'm awfully sorry about this.\" William was furious! He finally decided to go to his mother with the news. \"Dad has done so much harm.. I guess I'm never going to get married,\" he complained. \"Every time I fall in love, Dad tells me the girl is my half-sister.\" His mother just shook her head. \"Don't pay any attention to what he says, dear. He's not really your father.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>A man piloting a hot air balloon discovers he has wandered off course and is hopelessly lost. He descends to a lower altitude and locates a man down on the ground. He lowers the balloon further and shouts, \"Excuse me, can you tell me where I am?\" The man below says, \"Yes, you're in a hot air balloon, about 30 feet above this field.\" \"You must work in Information Technology,\" says the balloonist. \"Yes I do,\" replies the man. \"And how did you know that?\" \"Well,\" says the balloonist, \"what you told me is technically correct, but of no use to anyone.\" The man below says, \"You must work in management.\" \"I do,\" replies the balloonist, \"how did you know?\" \"Well,\" says the man, \"you don't know where you are, or where you're going, but you expect my immediate help. You're in the same position you were before we met, but now it's my fault!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>On the first day of college, the Dean addressed the students, pointing out some of the rules: \"The female dormitory will be out-of-bounds for all male students and the male dormitory to the female students. Anybody caught breaking this rule will be finded $20 the first time.\" He continued, \"Anybody caught breaking this rule the second time will be fined $60. Being caught a third time will cost you a fine of $180. Are there any questions?\" At this point, a male student in the crowd inquired: \"How much for a season pass?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>105</td>\n",
       "      <td>A couple of hunters are out in the woods in the deep south when one of them falls to the ground. He doesn't seem to be breathing, and his eyes are rolled back in his head. The other guy whips out his cell phone and calls 911. He gasps to the operator, \"My friend is dead! What can I do?\" The operator, in a calm and soothing voice, says, \"Alright, take it easy. I can help. First, let's make sure he's dead.\" There is silence, and then a gun shot is heard. The hunter comes back on the line. \"Okay. Now what??\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke-id  \\\n",
       "34        35   \n",
       "52        53   \n",
       "67        68   \n",
       "71        72   \n",
       "104      105   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Text  \n",
       "34                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   An explorer in the deepest Amazon suddenly finds himself surrounded by a bloodthirsty group of natives. Upon surveying the situation, he says quietly to himself, \"Oh God, I'm screwed.\" The sky darkens and a voice booms out, \"No, you are NOT screwed. Pick up that stone at your feet and bash in the head of the chief standing in front of you.\" So with the stone he bashes the life out of the chief. He stands above the lifeless body, breathing heavily and looking at 100 angry natives... The voice booms out again, \"Okay....NOW you're screwed.\"  \n",
       "52    One Sunday morning William burst into the living room and said, \"Dad! Mom! I have some great news for you! I am getting married to the most beautiful girl in town. She lives a block away and her name is Susan.\" After dinner, William's dad took him aside. \"Son, I have to talk with you. Your mother and I have been married 30 years. She's a wonderful wife but she has never offered much excitement in the bedroom, so I used to fool around with women a lot. Susan is actually your half-sister, and I'm afraid you can't marry her.\" William was heart-broken. After eight months he eventually started dating girls again. A year later he came home and very proudly announced, \"Dianne said yes! We're getting married in June.\" Again his father insisted on another private conversation and broke the sad news. \"Dianne is your half-sister too, William. I'm awfully sorry about this.\" William was furious! He finally decided to go to his mother with the news. \"Dad has done so much harm.. I guess I'm never going to get married,\" he complained. \"Every time I fall in love, Dad tells me the girl is my half-sister.\" His mother just shook her head. \"Don't pay any attention to what he says, dear. He's not really your father.\"  \n",
       "67                                                                                                                                                                                                                                                                                                                                                                                        A man piloting a hot air balloon discovers he has wandered off course and is hopelessly lost. He descends to a lower altitude and locates a man down on the ground. He lowers the balloon further and shouts, \"Excuse me, can you tell me where I am?\" The man below says, \"Yes, you're in a hot air balloon, about 30 feet above this field.\" \"You must work in Information Technology,\" says the balloonist. \"Yes I do,\" replies the man. \"And how did you know that?\" \"Well,\" says the balloonist, \"what you told me is technically correct, but of no use to anyone.\" The man below says, \"You must work in management.\" \"I do,\" replies the balloonist, \"how did you know?\" \"Well,\" says the man, \"you don't know where you are, or where you're going, but you expect my immediate help. You're in the same position you were before we met, but now it's my fault!\"  \n",
       "71                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     On the first day of college, the Dean addressed the students, pointing out some of the rules: \"The female dormitory will be out-of-bounds for all male students and the male dormitory to the female students. Anybody caught breaking this rule will be finded $20 the first time.\" He continued, \"Anybody caught breaking this rule the second time will be fined $60. Being caught a third time will cost you a fine of $180. Are there any questions?\" At this point, a male student in the crowd inquired: \"How much for a season pass?\"  \n",
       "104                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   A couple of hunters are out in the woods in the deep south when one of them falls to the ground. He doesn't seem to be breathing, and his eyes are rolled back in his head. The other guy whips out his cell phone and calls 911. He gasps to the operator, \"My friend is dead! What can I do?\" The operator, in a calm and soothing voice, says, \"Alright, take it easy. I can help. First, let's make sure he's dead.\" There is silence, and then a gun shot is heard. The hunter comes back on the line. \"Okay. Now what??\"  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_SGD_recommendations(user_id,ratings_df,pred_utility,Utility):\n",
    "    #Get the list of jokes, which are already rated by the user:\n",
    "    already_rated = list(ratings_df[(ratings_df[\"user_id\"] == user_id)][\"item_id\"])\n",
    "    \n",
    "    top_user_ratings = ratings_df[(ratings_df[\"user_id\"] == user_id)].sort([\"rating\"],ascending=[0]).head(5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Note that the joke IDs are NOT named using consecutive integers\n",
    "    #Get the items not rated by the user ID\n",
    "    not_rated = set(ratings_df[\"item_id\"]) - set(already_rated)\n",
    "    \n",
    "    \n",
    "    row_idx = [user_id] * len(not_rated)\n",
    "    col_idx = list(not_rated)\n",
    "    #Convert pred matrix to data frame\n",
    "    pred_df = pd.DataFrame(pred)\n",
    "    \n",
    "    #Change the row and column names\n",
    "    pred_df.index = Utility.index\n",
    "    pred_df.columns = Utility.columns\n",
    "    \n",
    "    #Get ratings at the intersection of the rows and columns list\n",
    "    ratings = get_ratings(pred_df,row_idx,col_idx,indices=True)\n",
    "    \n",
    "    ratings = np.array(ratings)\n",
    "    \n",
    "    #Change the ratings to the allowed interval\n",
    "    ratings[ratings > 10] = 10\n",
    "    ratings[ratings < -10] = -10\n",
    "    return [ratings,row_idx,col_idx,top_user_ratings]\n",
    "    \n",
    "#Predict the ratings for the user ID 129\n",
    "user_id = 129\n",
    "pred_ratings,row_idx,col_idx,top_user_ratings = get_SGD_recommendations(user_id,ratings_df,pred,Utility)\n",
    "print \"The user ID {} has rated these jokes high (top 5 jokes):\".format(user_id)\n",
    "display(top_user_ratings)\n",
    "\n",
    "display(items_df[items_df[\"Joke-id\"].isin(list(top_user_ratings[\"item_id\"]))])\n",
    "\n",
    "display_df=pd.DataFrame(zip(row_idx,col_idx,pred_ratings),columns=[\"user_id\",\"item_id\",\"predicted_ratings\"])\n",
    "\n",
    "display_df[\"predicted_ratings\"].min()\n",
    "display_df=display_df.sort([\"predicted_ratings\"],ascending=0)\n",
    "\n",
    "recommended_items = list(display_df[\"item_id\"])[0:5]\n",
    "print \"Top 5 recommended items for the user ID: {} are given below.\".format(user_id)\n",
    "items_df[items_df[\"Joke-id\"].isin(recommended_items)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above display shows that the user ID 129 has rated all the jokes with a negative rating. But our recommender is still able to predict the jokes he likes. But NOTE that we cannot determine if he really likes these jokes, unless we present these jokes to the user and capture his response.\n",
    "\n",
    "Let us get the recommended jokes for the user ID 17:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user ID 17 has rated these jokes high (top 5 jokes):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "      <td>9.938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  item_id  rating\n",
       "755       17       17  10.000\n",
       "766       17       35  10.000\n",
       "771       17       49  10.000\n",
       "758       17       20  10.000\n",
       "770       17       27   9.938"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>How many men does it take to screw in a light bulb? One. Men will screw anything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>What's the difference between a Macintosh and an Etch-a-Sketch? You don't have to shake the Mac to clear the screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Bill Clinton returns from a vacation in Arkansas and walks down the steps of Air Force One with two pigs under his arms. At the bottom of the steps, he says to the honor guardsman, \"These are genuine Arkansas Razor-Back Hogs. I got this one for Chelsea and this one for Hillary.\" The guardsman replies, \"Nice trade, Sir.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>An explorer in the deepest Amazon suddenly finds himself surrounded by a bloodthirsty group of natives. Upon surveying the situation, he says quietly to himself, \"Oh God, I'm screwed.\" The sky darkens and a voice booms out, \"No, you are NOT screwed. Pick up that stone at your feet and bash in the head of the chief standing in front of you.\" So with the stone he bashes the life out of the chief. He stands above the lifeless body, breathing heavily and looking at 100 angry natives... The voice booms out again, \"Okay....NOW you're screwed.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>Three engineering students were gathered together discussing the possible designers of the human body. One said, \"It was a mechanical engineer. Just look at all the joints.\" Another said, \"No, it was an electrical engineer. The nervous systems many thousands of electrical connections.\" The last said, \"Actually, it was a civil engineer. Who else would run a toxic waste pipeline through a recreational area?\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Joke-id  \\\n",
       "16       17   \n",
       "19       20   \n",
       "26       27   \n",
       "34       35   \n",
       "48       49   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Text  \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 How many men does it take to screw in a light bulb? One. Men will screw anything.  \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                                              What's the difference between a Macintosh and an Etch-a-Sketch? You don't have to shake the Mac to clear the screen.  \n",
       "26                                                                                                                                                                                                                                 Bill Clinton returns from a vacation in Arkansas and walks down the steps of Air Force One with two pigs under his arms. At the bottom of the steps, he says to the honor guardsman, \"These are genuine Arkansas Razor-Back Hogs. I got this one for Chelsea and this one for Hillary.\" The guardsman replies, \"Nice trade, Sir.\"  \n",
       "34   An explorer in the deepest Amazon suddenly finds himself surrounded by a bloodthirsty group of natives. Upon surveying the situation, he says quietly to himself, \"Oh God, I'm screwed.\" The sky darkens and a voice booms out, \"No, you are NOT screwed. Pick up that stone at your feet and bash in the head of the chief standing in front of you.\" So with the stone he bashes the life out of the chief. He stands above the lifeless body, breathing heavily and looking at 100 angry natives... The voice booms out again, \"Okay....NOW you're screwed.\"  \n",
       "48                                                                                                                                         Three engineering students were gathered together discussing the possible designers of the human body. One said, \"It was a mechanical engineer. Just look at all the joints.\" Another said, \"No, it was an electrical engineer. The nervous systems many thousands of electrical connections.\" The last said, \"Actually, it was a civil engineer. Who else would run a toxic waste pipeline through a recreational area?\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommended items for the user ID: 17 are given below.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke-id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>An engineer, a physicist and a mathematician are sleeping in a room. There is a fire in the room. The engineer wakes up, sees the fire, picks up the bucket of water and douses the fire and goes back to sleep. Again there is a fire in the room. This time, the physicist wakes up, notices the bucket, fills it with water, calculates the optimal trajectory and douses the fire in minimum amount of water and goes back to sleep. Again there is a fire. This time the mathematician wakes up. He looks at the fire, looks at the bucket and the water and exclaims, \"A solution exists!\" and goes back to sleep.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Age and Womanhood 1. Between the ages of 13 and 18... She is like Africa, virgin and unexplored. 2. Between the ages of 19 and 35... She is like Asia, hot and exotic. 3. Between the ages of 36 and 45... She is like America, fully explored, breathtakingly beautiful, and free with her resources. 4. Between the ages of 46 and 56... She is like Europe, exhausted but still has points of interest. 5. After 56 she is like Australia... Everybody knows it's down there, but who gives a damn?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>As a pre-med student, I had to take a difficult class in physics. One day our professor was discussing a particularly complicated concept. A student rudely interrupted to ask, \"Why do we have to learn this stuff?\" \"To save lives.\" The professor responded quickly and continued the lecture. A few minutes later, the same student spoke up again. \"So how does physics save lives?\" he persisted. \"It usually keeps the idiots like you out of medical school,\" replied the professor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>105</td>\n",
       "      <td>A couple of hunters are out in the woods in the deep south when one of them falls to the ground. He doesn't seem to be breathing, and his eyes are rolled back in his head. The other guy whips out his cell phone and calls 911. He gasps to the operator, \"My friend is dead! What can I do?\" The operator, in a calm and soothing voice, says, \"Alright, take it easy. I can help. First, let's make sure he's dead.\" There is silence, and then a gun shot is heard. The hunter comes back on the line. \"Okay. Now what??\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>An engineer dies and reports to the pearly gates. St. Peter checks his dossier and says, \"Ah, you''re an engineer--you're in the wrong place.\" So, the engineer reports to the gates of hell and is let in. Pretty soon, the engineer gets dissatisfied with the level of comfort in hell, and starts designing and building improvements. After awhile, they've got air conditioning, flush toilets and escalators, and the engineer is a pretty popular guy. One day, God calls Satan up on the telephone and says with a sneer, \"So, how's it going down there in hell?\" Satan replies, \"Hey, things are going great. We've got air conditioning, flush toilets and escalators, and there's no telling what this engineer is going to come up with next.\" God replies, \"What?? You've got an engineer? That's a mistake--he should never have gotten down there; send him up here.\" Satan says, \"No way.\" I like having an engineer on the staff, and I'm keeping him.\" God says, \"Send him back up here or I'll sue.\" Satan laughs uproariously and answers, \"Yeah, right. And just where are YOU going to get a lawyer?\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke-id  \\\n",
       "62        63   \n",
       "97        98   \n",
       "103      104   \n",
       "104      105   \n",
       "105      106   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Text  \n",
       "62                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         An engineer, a physicist and a mathematician are sleeping in a room. There is a fire in the room. The engineer wakes up, sees the fire, picks up the bucket of water and douses the fire and goes back to sleep. Again there is a fire in the room. This time, the physicist wakes up, notices the bucket, fills it with water, calculates the optimal trajectory and douses the fire in minimum amount of water and goes back to sleep. Again there is a fire. This time the mathematician wakes up. He looks at the fire, looks at the bucket and the water and exclaims, \"A solution exists!\" and goes back to sleep.  \n",
       "97                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Age and Womanhood 1. Between the ages of 13 and 18... She is like Africa, virgin and unexplored. 2. Between the ages of 19 and 35... She is like Asia, hot and exotic. 3. Between the ages of 36 and 45... She is like America, fully explored, breathtakingly beautiful, and free with her resources. 4. Between the ages of 46 and 56... She is like Europe, exhausted but still has points of interest. 5. After 56 she is like Australia... Everybody knows it's down there, but who gives a damn?  \n",
       "103                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    As a pre-med student, I had to take a difficult class in physics. One day our professor was discussing a particularly complicated concept. A student rudely interrupted to ask, \"Why do we have to learn this stuff?\" \"To save lives.\" The professor responded quickly and continued the lecture. A few minutes later, the same student spoke up again. \"So how does physics save lives?\" he persisted. \"It usually keeps the idiots like you out of medical school,\" replied the professor.  \n",
       "104                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  A couple of hunters are out in the woods in the deep south when one of them falls to the ground. He doesn't seem to be breathing, and his eyes are rolled back in his head. The other guy whips out his cell phone and calls 911. He gasps to the operator, \"My friend is dead! What can I do?\" The operator, in a calm and soothing voice, says, \"Alright, take it easy. I can help. First, let's make sure he's dead.\" There is silence, and then a gun shot is heard. The hunter comes back on the line. \"Okay. Now what??\"  \n",
       "105   An engineer dies and reports to the pearly gates. St. Peter checks his dossier and says, \"Ah, you''re an engineer--you're in the wrong place.\" So, the engineer reports to the gates of hell and is let in. Pretty soon, the engineer gets dissatisfied with the level of comfort in hell, and starts designing and building improvements. After awhile, they've got air conditioning, flush toilets and escalators, and the engineer is a pretty popular guy. One day, God calls Satan up on the telephone and says with a sneer, \"So, how's it going down there in hell?\" Satan replies, \"Hey, things are going great. We've got air conditioning, flush toilets and escalators, and there's no telling what this engineer is going to come up with next.\" God replies, \"What?? You've got an engineer? That's a mistake--he should never have gotten down there; send him up here.\" Satan says, \"No way.\" I like having an engineer on the staff, and I'm keeping him.\" God says, \"Send him back up here or I'll sue.\" Satan laughs uproariously and answers, \"Yeah, right. And just where are YOU going to get a lawyer?\"  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 17\n",
    "pred_ratings,row_idx,col_idx,top_user_ratings = get_SGD_recommendations(user_id,ratings_df,pred,Utility)\n",
    "print \"The user ID {} has rated these jokes high (top 5 jokes):\".format(user_id)\n",
    "display(top_user_ratings)\n",
    "\n",
    "display(items_df[items_df[\"Joke-id\"].isin(list(top_user_ratings[\"item_id\"]))])\n",
    "\n",
    "display_df=pd.DataFrame(zip(row_idx,col_idx,pred_ratings),columns=[\"user_id\",\"item_id\",\"predicted_ratings\"])\n",
    "\n",
    "display_df[\"predicted_ratings\"].min()\n",
    "display_df=display_df.sort([\"predicted_ratings\"],ascending=0)\n",
    "\n",
    "recommended_items = list(display_df[\"item_id\"])[0:5]\n",
    "print \"Top 5 recommended items for the user ID: {} are given below.\".format(user_id)\n",
    "items_df[items_df[\"Joke-id\"].isin(recommended_items)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can see that the user liked a joke related to engineering students' topic, and the recommended jokes 63 and 106 are about engineers and 104 is about pre-med *student*. But the recommended jokes are different from the jokes recommended by the collaborative filtering algorithm (which recommended the jokes with IDs: 26, 39, 47,64,105,126). Hence, except the 105 joke, both recommenders have recommended different jokes. Now to determine which recommendation system is superior, we need to perform A/B testing by capturing the real responses from the users. But we can certainly confirm that the SGD algorithm is doing a satisfactory job, since we obtained an AUC scores between 0.8 and 0.85 (for most of the test runs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Conclusion\n",
    "In this project, we developed 2 algorithms to make joke recommendations:\n",
    "* A Collaborative filtering algorithm based on the cosine similarity and the number of user ratings\n",
    "* Stochastic Gradient Descent method based on the matrix factorization\n",
    "\n",
    "For recommendations based on the collaborative filtering, we identified the recommended jokes based on cosine similarity, and if the joke pairs were rated by at least 1000 users. These criteria has given good recommendations. However, this method has the following drabacks:\n",
    "\n",
    "1. For a new user we do not have a good mechanism to provide recommendations (the cold start problem).\n",
    "\n",
    "2. We assumed that a rating of greater than 5 implies that the user has liked the joke. This assumption might be incorrect. Based on this criterion, we may not have any jokes to recommend, if a user gives a rating of less than 5 for all the jokes s/he reads.\n",
    "\n",
    "3. We also restricted the recommended items to the list which were rated by at least 1000 users. This criterion will decrease the number of potential recommendations to the users.\n",
    "\n",
    "4. For new items, we do not have any ratings available, and we never recommend the new items based on the selection criteria of 1000 common ratings with at least another item. \n",
    "\n",
    "For SGD based recommender, we have the following advantages:\n",
    "\n",
    "1. We are able to predict the ratings for all the items for all the users.\n",
    "\n",
    "2. We were able to identify optimal rating threshold as 5 to determine if a user likes the item.\n",
    "\n",
    "3. We were able to run the algorithm on a laptop with 16GB of RAM (the ratings data set has 1.7 Million ratings)\n",
    "\n",
    "4. We were able to quantify the performance of our algorithm using AUC (Area Under the Curve), and obtained an average AUC score of 0.8, which is a good score since it is way higher than the AUC score of 0.5 (obtained by random guessing).\n",
    "\n",
    "However the SGD method also does not address cold start problem.\n",
    "\n",
    "### Future work\n",
    "I would like to address the following as a part of future work:\n",
    "\n",
    "* Analyze methods to address the cold start problem.\n",
    "\n",
    "* Build many recommenders, combine their outputs and analyze if the quality of the recommendations improve.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "1. Eigentaste: A Constant Time Collaborative Filtering Algorithm. Ken Goldberg, Theresa Roeder, Dhruv Gupta, and Chris Perkins. Information Retrieval, 4(2), 133-151. July 2001\n",
    "\n",
    "2. Jure Leskovec, Anand Rajaraman and Jeffrey D. Ullman 2014. Mining of Massive Datasets (Chapter 9)\n",
    "\n",
    "3. Deepak K. Agarwal and Bee-Chung Chen. Statistical Methods for Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix - A\n",
    "\n",
    "The implementation of the cosine similarity computation process is explained using a small data set. The same logic is applicable to the massive data sets.\n",
    "\n",
    "## Example:\n",
    "\n",
    "Let us assume that we have the following ratings for some of the jokes:\n",
    "\n",
    "<img src=\"toy-example.png\">\n",
    "\n",
    "The above figure shows the normalized ratings. These normalized ratings will be converted to an RDD with user ID as the key (the RDD is displayed below):\n",
    "\n",
    "<img src=\"RDD-1.png\">\n",
    "\n",
    "Let us consider the first element highlighted in red color. This element specifies that the user ID 1 has given a normalized rating of -2.2 to joke 1. The second element highlighted in blue color specifies that the user ID 1 has given a normalized rating of -5.7 to joke 4.\n",
    "\n",
    "This RDD is self-joined with itself (on the join condition of USER-ID = USER-ID). The resultant RDD is filtered further to avoid duplicate combinations. For example, for the user ID 4, we will get the following elements (not all permutations are shown):\n",
    "\n",
    "<img src=\"RDD-2a.png\">\n",
    "\n",
    "Consider the second element of the above list. (4, ((1, -6.5), (1, -6.5))), which is highlighted in red. This element is showing the combination of the same joke ID 1. Such elements can be eliminated. Consider third and 4th elements: (4, ((2, -5.0),(1, -6.5))),\n",
    "(4, ((1, -6.5), (2, -5.0))), which are highlighted in green and blue respectively. Both represent the same combinations. We only need one element from such duplicate combinations. So, we will filter the elements and include only the elements if and only if the joke ID of the first value is less than the joke ID of the second value. This filter condition will eliminate the second and third rows. When the same condition is applied on the whole data set, we will get the following elements:\n",
    "\n",
    "<img src=\"RDD-2.png\">\n",
    "\n",
    "The above RDD is further reduced, by extracting the joke IDs from the values, making the joke IDs as the keys and making the ratings as the values. Note that the user ID is dropped. We will get the following RDD:\n",
    "\n",
    "<img src=\"RDD-3.png\">\n",
    "\n",
    "\n",
    "The above RDD shows the combinations/pairs of jokes, which are rated by at least one user. For example, one user (highlighted in red) has rated the jokes (1,4) pairs as (-2.2, -5.7) and another user (highlighted in blue) has rated the same joke pairs as (-5.25, -2.75). This RDD is further reduced by grouping the keys (joke pairs) and getting the cosine similarity between the values. For example, for the joke pairs (1,4), we have the following ratings provided by two users: (-2.2, -5.7) and (-5.25, -2.75). Getting the cosine similarity between the vectors $[-2.2, -5.25]$ and $[-5.7, -2.75]$ give us 0.7518. This measure is captured along with the number of users who rated both the movies (in this example, we have 2 users who rated 1,4 movies)\n",
    "\n",
    "This filter will give us the following RDD:\n",
    "\n",
    "<img src=\"RDD-4.png\">\n",
    "\n",
    "The above RDD is written to a HDFS file, and this data set will be used to provide recommendations. For instance, if a user has liked the joke-6, and he has not seen the joke-1, then we can recommend joke-1 to him, since the cosine similarity is 0.95.\n",
    "\n",
    "The following code block shows the actual Python code written using PySpark to obtain the cosine similarity of the example data set shown above. This code was written on windows machine with 6 GB RAM, running Spark. The same code (with minor modifications) will be used to run on the bigger data set (with 1.7 Million ratings) on a Hadoop cluster. NOTE that the following code does NOT normalize the ratings automatically. But we will be supplying the data set with normalized ratings as input. But in the implementation of the same program in Hadoop environment, we will also include the logic to normalize the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from math import sqrt\n",
    "import sys\n",
    "\n",
    "## Function to remove duplicate ratings\n",
    "def filterDuplicates((userID, ratings)):\n",
    "    (joke1,rating1) = ratings[0]\n",
    "    (joke2,rating2) = ratings[1]\n",
    "    return joke1 < joke2\n",
    " \n",
    "## Cosine similarity function    \n",
    "def computeCosineSimilarity(ratingPairs):\n",
    "    numPairs = 0\n",
    "    sum_xx = sum_yy = sum_xy = 0\n",
    "    for ratingX, ratingY in ratingPairs:\n",
    "        sum_xx += ratingX * ratingX\n",
    "        sum_yy += ratingY * ratingY\n",
    "        sum_xy += ratingX * ratingY\n",
    "        numPairs += 1\n",
    " \n",
    "    numerator = sum_xy\n",
    "    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n",
    " \n",
    "    score = 0\n",
    "    if (denominator):\n",
    "        score = (numerator / (float(denominator)))\n",
    " \n",
    "    return (score, numPairs)\n",
    " \n",
    "## Make joke pairs as the keys, and their ratings as the values    \n",
    "def makePairs((user, ratings)):\n",
    "    (joke1, rating1) = ratings[0]\n",
    "    (joke2, rating2) = ratings[1]\n",
    "    return ((joke1, joke2), (rating1, rating2))\n",
    " \n",
    "\n",
    "## Define conf object to run on local machine    \n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Ratings..\")\n",
    "\n",
    "## Define SparkContext\n",
    "sc = SparkContext(conf = conf)\n",
    " \n",
    "data = sc.textFile(\"toy_data.csv\")\n",
    "\n",
    "\n",
    "print \"Read the file...\"\n",
    "ratings = data.map(lambda x: x.split(\",\")).map(lambda x: (int(x[0]),(int(x[1]),float(x[2]))))\n",
    "\n",
    "display_df = ratings.collect()\n",
    "\n",
    "for i in display_df:\n",
    "    print i\n",
    "\n",
    "print \"Prepared the ratings RDD...\"\n",
    "\n",
    "## Have to partition the data set when running on a cluster\n",
    "#ratingsPartitioned = ratings.partitionBy(100)\n",
    "#print \"Partitioned the ratings into 100 parts...\"\n",
    "\n",
    "ratingsPartitioned = ratings\n",
    "\n",
    "## Self Join\n",
    "joinedRatings = ratingsPartitioned.join(ratingsPartitioned)\n",
    "print \"Self join completed ...\"\n",
    " \n",
    "##Filter duplicate ratings in the join RDD    \n",
    "uniqueJoinedRatings = joinedRatings.filter(filterDuplicates)\n",
    "print \"Filtered the duplicates...\"\n",
    "\n",
    "display_df = uniqueJoinedRatings.collect()\n",
    "\n",
    "for i in display_df:\n",
    "    print i\n",
    "\n",
    "\n",
    "#jokePairs = uniqueJoinedRatings.map(makePairs).partitionBy(100)\n",
    "jokePairs = uniqueJoinedRatings.map(makePairs)\n",
    "\n",
    "\n",
    "display_df = jokePairs.collect()\n",
    "\n",
    "for i in display_df:\n",
    "    print i\n",
    "\n",
    "jokePairRatings = jokePairs.groupByKey()\n",
    "\n",
    "print \"Computing the cosine similarity ...\"\n",
    "jokePairSimilarities = jokePairRatings.mapValues(computeCosineSimilarity).persist()\n",
    " \n",
    "print \"Sorting the results...\"\n",
    " \n",
    "jokePairSimilarities.sortByKey()\n",
    "\n",
    "display_df = jokePairSimilarities.collect()\n",
    "for i in display_df:\n",
    "    print i\n",
    "\n",
    "print \"Saving the results...\"\n",
    "jokePairSimilarities.saveAsTextFile(\"joke-sims\")\n",
    "\n",
    "print \"script ends...\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix-B\n",
    "\n",
    "## Downloading the files and running the pyspark program\n",
    "\n",
    "FTP the jester_ratings.dat file to a directory in Linux machine, and move the file jester_ratings.dat to the HDFS filesystem, using the following command:\n",
    "\n",
    "       hadoop fs -put <local_directory>/jester_ratings.dat  <hadoop_dir> \n",
    "\n",
    "To run the pyspark program in Hadoop, use the following command:\n",
    "\n",
    "       spark-submit --master yarn-client --executor-memory 1g <program_name>\n",
    "\n",
    "The program will create 100 files in HDFS (since we used 100 partitions in our pyspark program). To combine these 100 files and download to the local Linux folder, run the following command:\n",
    "\n",
    "       hadoop fs -getmerge <Hadoop home dir>/joke-sims/ jokes_sim.txt\n",
    "\n",
    "\n",
    "**Example:**\n",
    "\n",
    "If you have downloaded jester_ratings.dat to /home/sekhar/ directory, you may copy the file to Hadoop File system as follows:\n",
    "\n",
    "1. Create a HDFS directory \"data\" in /user/sekhar directory (which is in HDFS), use the following command: \n",
    "\n",
    "        hadoop fs -mkdir /user/sekhar/data  \n",
    "        \n",
    "2. To copy the downloaded file to /user/sekhar/data HDFS directory, use the following command:\n",
    "        \n",
    "        hadoop fs -put /home/sekhar/jester_ratings.dat  /user/sekhar/data\n",
    "\n",
    "3. To run the pyspark program which finds the similarity score, copy the code given in the next block to a file on one of the linux machines in the cluster. For example, if you have copied the code to the file jester_1.py, execute the following command to run:\n",
    "\n",
    "        spark-submit --master yarn-client --executor-memory 1g jester_1.py\n",
    "\n",
    "4. The above command will create 100 HDFS files. These files can be combined into one file and can be downloaded to a local Linux directory:\n",
    "\n",
    "        hadoop fs -getmerge /user/sekhar/joke-sims/ jokes_sim.txt\n",
    "       \n",
    "where /user/sekhar/ is the Hadoop home directory, where the files are created. The joke-sims directory in /user/sekhar/ contains the 100 files.\n",
    "\n",
    "Download the jokes_sim.txt to your local machine, and perform the analysis. This file contains the similarity scores between the jokes.\n",
    "\n",
    "\n",
    "PySpark code to compute the cosine similarity between the pairs of jokes rated by at least one user is given below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "##To run: Copy this program to a file named \"jester_1.py\" and execute the following command:\n",
    "## spark-submit --master yarn-client --executor-memory 1g jester_1.py\n",
    "\n",
    "## Logic:\n",
    "## The following steps will normalize the ratings:\n",
    "## 1. Get the average ratings of all the users given to various items\n",
    "## 2. Get the average ratings of all the items given by various users \n",
    "## 3. Subtract the average ratings of the respective user and the respective item\n",
    "##    from the actual rating given by a user to an item\n",
    "## The following step will compute the cosine similarity between all the pairs of jokes\n",
    "## which are rated by at least one user\n",
    "## 4. Compute the cosine similarity between the pairs of jokes\n",
    "##\n",
    "\n",
    "print \"Starting the script ...\"\n",
    "\n",
    "## filterDuplicates will remove the duplicates \n",
    "def filterDuplicates( (userID, ratings) ):\n",
    "    (joke1, rating1) = ratings[0]\n",
    "    (joke2, rating2) = ratings[1]\n",
    "    return joke1 < joke2\n",
    "\n",
    "## computeCosineSimilarity will compute the cosine similarity\n",
    "def computeCosineSimilarity(ratingPairs):\n",
    "    numPairs = 0\n",
    "    sum_xx = sum_yy = sum_xy = 0\n",
    "    for ratingX, ratingY in ratingPairs:\n",
    "        sum_xx += ratingX * ratingX\n",
    "        sum_yy += ratingY * ratingY\n",
    "        sum_xy += ratingX * ratingY\n",
    "        numPairs += 1\n",
    "\n",
    "    numerator = sum_xy\n",
    "    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n",
    "\n",
    "    score = 0\n",
    "    if (denominator):\n",
    "        score = (numerator / (float(denominator)))\n",
    "\n",
    "    return (score, numPairs)\n",
    "\n",
    "## makes the pairs of jokes as the keys, and their ratings as the values\n",
    "def makePairs((user, ratings)):\n",
    "    (joke1, rating1) = ratings[0]\n",
    "    (joke2, rating2) = ratings[1]\n",
    "    return ((joke1, joke2), (rating1, rating2))\n",
    "\n",
    "## Subtract the users average ratings from the jokes ratings.\n",
    "## The output RDD will have the joke ID as the key\n",
    "def normalizeByUser((user_id,ratings)):\n",
    "    (part_1,avg) = ratings\n",
    "    normalized=part_1[1] - avg\n",
    "    #The key will be the joke ID in the returned RDD\n",
    "    return (part_1[0],(user_id,normalized))\n",
    "## Subtract the jokes average ratings from the respective jokes\n",
    "## The input RDD will be the result of the join between the RDD \n",
    "## obtained by normalizeByUser() function, and the average jokes ratings RDD\n",
    "## The output of this function will be an RDD with user ID as the key\n",
    "def normalizeByJoke((joke_id,ratings)):\n",
    "    (part_1,avg) = ratings\n",
    "    normalized=part_1[1] - avg\n",
    "    #The key will be the user ID in the returned RDD\n",
    "    return (part_1[0],(joke_id,normalized))\n",
    "\n",
    "\n",
    "## Main script\n",
    "conf = SparkConf()\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "data = sc.textFile(\"hdfs:///user/a152700/data/jester_ratings.dat\")\n",
    "\n",
    "##To test on toy.csv data set, uncomment the following statement, and comment the \n",
    "##above statement\n",
    "#data = sc.textFile(\"file:///home/a152700/spark/programs/toy.csv\")\n",
    "print \"Read the file...\"\n",
    "joke_ratings = data.map(lambda x: x.split()).map(lambda x: (int(x[1]),float(x[2])))\n",
    "user_ratings = data.map(lambda x: x.split()).map(lambda x: (int(x[0]),float(x[2])))\n",
    "ratings = data.map(lambda x: x.split()).map(lambda x: (int(x[0]),(int(x[1]),float(x[2]))))\n",
    "\n",
    "print \"Prepared the ratings RDD...\"\n",
    "\n",
    "joke_ratingsPartitioned = joke_ratings.partitionBy(100)\n",
    "print \"Partitioned the joke ratings into 100 parts...\"\n",
    "\n",
    "user_ratingsPartitioned = user_ratings.partitionBy(100)\n",
    "print \"Partitioned the user ratings into 100 parts...\"\n",
    "\n",
    "ratingsPartitioned = ratings.partitionBy(100)\n",
    "print \"Partitioned the whole  ratings into 100 parts...\"\n",
    "\n",
    "##Get the average joke ratings\n",
    "joke_ratings_rdd = joke_ratings.mapValues(lambda x: (x,1)).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "joke_ratings_avg = joke_ratings_rdd.mapValues(lambda x: x[0]/x[1]).persist()\n",
    "\n",
    "##Get the average user ratings\n",
    "user_ratings_rdd = user_ratings.mapValues(lambda x: (x,1)).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "user_ratings_avg = user_ratings_rdd.mapValues(lambda x: x[0]/x[1]).persist()\n",
    "\n",
    "#Joining user_ratings_avg and ratings\n",
    "user_ratings_joined = ratingsPartitioned.join(user_ratings_avg)\n",
    "user_ratings_normalized = user_ratings_joined.map(normalizeByUser)\n",
    "#The user_ratings_normalized RDD will have the joke ID as the key\n",
    "#The ratings are normalized using the avg. user rating\n",
    "\n",
    "display_rdd = user_ratings_joined.collect()\n",
    "\n",
    "for i in range(10):\n",
    "     print display_rdd[i]\n",
    "\n",
    "display_rdd = user_ratings_normalized.collect()\n",
    "\n",
    "for i in range(10):\n",
    "     print display_rdd[i]\n",
    "\n",
    "\n",
    "\n",
    "#Joining joke_ratings_avg and ratings\n",
    "joke_ratings_joined = user_ratings_normalized.join(joke_ratings_avg)\n",
    "joke_ratings_normalized = joke_ratings_joined.map(normalizeByJoke) \n",
    "#The joke_ratings_normalized RDD will have the user ID as the key\n",
    "#The ratings are normalized using the avg. joke rating\n",
    "\n",
    "display_rdd = joke_ratings_normalized.collect()\n",
    "\n",
    "for i in range(10):\n",
    "     print display_rdd[i]\n",
    "\n",
    "\n",
    "#joke_ratings_avg_sorted = joke_ratings_avg.sortByKey() \n",
    "\n",
    "#joke_ratings_avg_sorted.saveAsTextFile(\"joke-avg\")\n",
    "\n",
    "#user_ratings_avg_sorted = user_ratings_avg.sortByKey()\n",
    "\n",
    "#user_ratings_avg_sorted.saveAsTextFile(\"user-avg\")\n",
    "\n",
    "\n",
    "\n",
    "#display_rdd = rdd.collect()\n",
    "\n",
    "#for i in range(10):\n",
    "#     print display_rdd[i]\n",
    "\n",
    "\n",
    "##Computing the similarities of jokes using the normalized ratings:\n",
    "##joke_ratings_normalized\n",
    "print \"Normalization of ratings complete...\"\n",
    "print \"Now computing the similarities...\"\n",
    "\n",
    "ratingsPartitioned = joke_ratings_normalized.partitionBy(100)\n",
    "\n",
    "print \"script ends...\"\n",
    "\n",
    "print \"Partitioned the ratings into 100 parts...\"\n",
    "\n",
    "joinedRatings = ratingsPartitioned.join(ratingsPartitioned)\n",
    "print \"Self join completed ...\"\n",
    "\n",
    "uniqueJoinedRatings = joinedRatings.filter(filterDuplicates)\n",
    "print \"Filtered the duplicates...\"\n",
    "\n",
    "jokePairs = uniqueJoinedRatings.map(makePairs).partitionBy(100)\n",
    "\n",
    "jokePairRatings = jokePairs.groupByKey()\n",
    "print \"Computing the cosine similarity ...\"\n",
    "jokePairSimilarities = jokePairRatings.mapValues(computeCosineSimilarity).persist()\n",
    "\n",
    "print \"Sorting the results...\"\n",
    "\n",
    "jokePairSimilarities.sortByKey()\n",
    "\n",
    "print \"Saving the results...\"\n",
    "jokePairSimilarities.saveAsTextFile(\"joke-sims\")\n",
    "display_rdd = jokePairSimilarities.collect()\n",
    "\n",
    "for i in range(10):\n",
    "     print display_rdd[i]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
