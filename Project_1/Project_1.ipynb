{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender systems - Project 1\n",
    "\n",
    "## Recommend wiki pages based on the current topic of interest\n",
    "\n",
    "### Abstract\n",
    "\n",
    "The main idea of this project is to build a content based recommender that recommends another document that the user might be interested to read, based on the current document s/he is reading. We will implement this project using TFIDF (Term Frequency - Inverse Document Frequency) method to assign a numeric score to each word in the document, and use K nearest neighbors technique to identify the related documents. Based on the current document of interest, we will display a set of documents nearest to the current document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF algorithm\n",
    "TFIDF (Term Frequency - Inverse Document Frequency) is one of the most popular text processing algorithms that helps us to accurately assign importance scores to each word in a document. At a very high level, the algorithm follows the following logic:\n",
    "\n",
    "1. Let $D = {d_1, d_2 ... d_n}$ be a set of documents. \n",
    "2. For each document $d$ in $D$ perform the following:\n",
    "\n",
    "    a. Get the frequencies of all the words in $d$. Call this as TF (Term Frequency) vector for document $d$\n",
    "\n",
    "3. Get the list of all unique words in all the documents, and for each unique word, get the number of documents containing the word. Let DF (Document Frequency) be the vector containing these counts. \n",
    "\n",
    "4. For each word in DF, get the following:\n",
    "\n",
    "    $$IDF_w=log(n/(1+\\mbox{number of documents containing the word }w))$$\n",
    "    The log can have any valid base. IDF stands for Inverse Document Frequency. \"n\" represents the total number of documents\n",
    "    \n",
    "5. For each document $d$, multiply the elements of $TF_d$ with the corresponding elements of IDF, to obtain TFIDF vector for document $d$. \n",
    "\n",
    "**Example:**\n",
    "\n",
    "Let us suppose that we have 64 documents, and 2 of the documents have the following phrases:\n",
    "$d_1$: \"sekhar mekala is a data science evangelist\"\n",
    "$d_2$: \"mekala sekhar\"\n",
    "\n",
    "The term frequency vectors of these two documents are given below:\n",
    "$$TF_1 = [\"sekhar\":1,\"mekala\":1,\"is\":1,\"a\":1,\"data\":1,\"science\":1,\"evangelist\":1]$$\n",
    "\n",
    "$$TF_2 = [\"sekhar\":1,\"mekala\":1]$$\n",
    "\n",
    "The DF vector is given below:\n",
    "$$DF = [\"sekhar\":2,\"mekala\":2,\"is\":61,\"a\":62,\"data\":5,\"science\":20,\"evangelist\":3 ....]$$\n",
    "\n",
    "The \".....\" in the DF vector represents the other words (in the remaining documents) and the number of documents containing those words. We do not need any details about the other words in other documents, since we will calculate the TFIDF of two documents only in this example. \n",
    "\n",
    "For \"sekhar\" the IDF score can be calculated as:\n",
    "$$log_{10} (64/(1+2)) = 1.33$$\n",
    "\n",
    "Based on the same logic, we can find the IDF vector as :\n",
    "$$IDF = [\"sekhar\":1.33,\"mekala\",1.33\",\"is\":0.014,\"a\":0.007,\"data\":1.03,\"science\":0.48,\"evangelist\":1.2 ....]$$\n",
    "\n",
    "Now we will get the product of corresponding elements of TF vectors (of each document) and the IDF vector:\n",
    "\n",
    "$$TFIDF_1 = [\"sekhar\":1.33,\"mekala\",1.33\",\"is\":0.014,\"a\":0.007,\"data\":1.03,\"science\":0.48,\"evangelist\":1.2, \"otherwords\":0 ....]$$\n",
    "\n",
    "$$TFIDF_2 = [\"sekhar\":1.33,\"mekala\",1.33\",\"otherwords\":0 ....]$$\n",
    "\n",
    "The TFIDF vectors show that the common words in a document (but rare in other documents) are scored higher than the words, which are common in all the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Manual implementation of TFIDF in python\n",
    "\n",
    "Import all the required packages first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Import all the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will implement the TFIDF algorithm manually. It creates a function named get_TFIDF(docs), where the input parameter \"docs\" will be a dictionary, in which all the keys represent the document IDs (unique identifiers), and the values of the keys will be the text of the respective document. The function will output a TFIDF data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_TFIDF(docs):\n",
    "        '''\n",
    "        The function get_TFIDF(docs) will accept a dictionary as input parm\n",
    "        Each key in the dictionary will represent unique document ID, and the \n",
    "        value will represent the document text\n",
    "        '''\n",
    "        ##Get the term frequencies in each document. \n",
    "        ##We will create a data frame in the format <doc ID>,<word>,<freq>. Each row can \n",
    "        ##belong to the same doc ID, but to a different word in the document. The \n",
    "        ##frequency of the words in the document are also listed\n",
    "\n",
    "        #Declare empty list objects\n",
    "        l1=[]\n",
    "        l2=[]\n",
    "\n",
    "        #Collect the key and values of the docs dict to two lists\n",
    "        for (k,d) in docs.items():\n",
    "            s = d.split()\n",
    "            l1.append([k]*len(s))\n",
    "            l2.append(s)\n",
    "\n",
    "        #Flatten the data (nested lists to a flat list)\n",
    "        l1= list(itertools.chain(*l1))\n",
    "        l2= list(itertools.chain(*l2))\n",
    "        #Create a data frame now\n",
    "        df = pd.DataFrame(zip(l1,l2),columns=[\"doc_id\",\"word\"])\n",
    "\n",
    "        #Group by the data and count the words in each document\n",
    "        TF=pd.DataFrame(df.groupby([\"doc_id\",\"word\"])[\"word\"].count())\n",
    "\n",
    "        #Assign the names to the indices, since we have \"word\" in two levels of indices, \n",
    "        #and we are getting conflit, when we are resetting the index\n",
    "        TF.index.names=[\"a\",\"b\"]\n",
    "\n",
    "        #Now reset he index\n",
    "        TF=pd.DataFrame(TF).reset_index()\n",
    "\n",
    "        #Name the columns\n",
    "        TF.columns=[\"ID\",\"word\",\"freq\"]\n",
    "        \n",
    "\n",
    "\n",
    "        ##Preparation of inverse document frequency (IDF) data frame.\n",
    "        ##We will get a data frame of the form <word>,<IDF>. The IDF \n",
    "        ##will be computed using a log to base 10, although\n",
    "        ##any log base can be used\n",
    "        IDF=TF.groupby([\"word\"]).count().reset_index()\n",
    "        IDF=IDF.drop(\"ID\",axis=1)\n",
    "        IDF[\"IDF\"] = np.log10(len(docs)/(IDF[\"freq\"]+1))\n",
    "        IDF=IDF.drop(\"freq\",axis=1)\n",
    "\n",
    "        ##Getting the TFIDF scores for each word in the documents\n",
    "        TFIDF=TF.join(IDF.set_index(\"word\"),on=\"word\",how=\"left\")\n",
    "        #print TFIDF\n",
    "        TFIDF[\"TFIDF\"] = TFIDF[\"freq\"] * TFIDF[\"IDF\"]\n",
    "\n",
    "        ##Drop the \"freq\" column, since it is of no use\n",
    "        TFIDF= TFIDF.drop([\"freq\",\"IDF\"],axis=1)\n",
    "\n",
    "        ##Pivot the data frame\n",
    "        TFIDF=TFIDF.pivot(index=\"ID\",columns=\"word\",values=\"TFIDF\").reset_index()\n",
    "\n",
    "        ##Rename the index name from word to \"\"\n",
    "        TFIDF.columns.name=\"\"\n",
    "\n",
    "        ##Fill the data frame with 0, where ever we have NA\n",
    "        TFIDF.fillna(value=0,inplace=True)\n",
    "        return TFIDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run the above function on a set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual runtime is 0.28200006485seconds\n",
      "[['d1' 0.0 0.7781512503836436 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.7781512503836436 0.0 0.0 0.0 0.0 0.0 0.7781512503836436 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
      " ['d10' 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.6020599913279624 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.7781512503836436 0.0 0.7781512503836436\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
      " ['d11' 0.47712125471966244 0.0 0.0 0.0 0.0 0.0 0.0 0.7781512503836436 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.6020599913279624 0.0 0.0 0.0 0.0]\n",
      " ['d12' 0.47712125471966244 0.0 0.0 0.0 0.0 0.7781512503836436 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.7781512503836436 0.0 0.0 0.0]\n",
      " ['d2' 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.6020599913279624\n",
      "  0.7781512503836436 0.0 0.0 0.0 0.0 0.7781512503836436 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
      " ['d3' 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.7781512503836436 0.0 0.0 0.0 0.0 0.0 0.0 0.7781512503836436 0.0 0.0\n",
      "  0.0 0.0 0.7781512503836436 0.0 0.7781512503836436]\n",
      " ['d4' 0.47712125471966244 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.7781512503836436 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.6020599913279624 0.0 0.0 0.0 0.0]\n",
      " ['d5' 0.0 0.0 0.0 0.7781512503836436 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.7781512503836436 0.0 0.0 0.7781512503836436 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.6020599913279624 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
      " ['d6' 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.6020599913279624 0.0 0.0 0.7781512503836436 0.0 0.0 0.0\n",
      "  0.7781512503836436 0.0 0.7781512503836436 0.0 0.0 0.0 0.0 0.0 0.0]\n",
      " ['d7' 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.7781512503836436 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.6020599913279624 0.0 0.0 0.0 0.0\n",
      "  0.7781512503836436 0.0 0.0 0.0 0.7781512503836436 0.0]\n",
      " ['d8' 0.0 0.0 0.7781512503836436 0.0 0.7781512503836436 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.6020599913279624 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0]\n",
      " ['d9' 0.0 0.0 0.0 0.0 0.0 0.0 0.7781512503836436 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.7781512503836436 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "  0.0 0.0 0.0 0.0 0.0 0.0]]\n"
     ]
    }
   ],
   "source": [
    "##Define a dictionary of documents:\n",
    "\n",
    "docs = {\"d1\":\"Julia Roberts Actress\", \"d2\":\"George Lucas Filmmaker\", \n",
    "\"d3\":\"Oprah Winfrey Television personality\",  \"d4\":\"Tom Hanks Actor\",  \n",
    "\"d5\":\"Michael Jordan Sportsperson Basketball\", \"d6\":\"The Rolling Stones Musicians\",  \n",
    "\"d7\":\"Tiger Woods Sportsperson Golf\",  \"d8\":\"Backstreet Boys Musicians\",  \n",
    "\"d9\":\"Cher Musician\",  \"d10\":\"Steven Spielberg Filmmaker\",\n",
    "       \"d11\":\"Tom Cruise Actor\",\"d12\":\"Bruce Willis Actor\"}\n",
    "\n",
    "#Start time capture\n",
    "start = time()\n",
    "TFIDF=get_TFIDF(docs)\n",
    "\n",
    "#End time capture\n",
    "end = time() \n",
    "\n",
    "print \"Manual runtime is {}seconds\".format(end-start)\n",
    "\n",
    "print np.array(TFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can see that our function get_TFIDF has created a TFIDF data frame. The run time of the code is displayed above. Most of the data in the data frame are zeros. This implies that using a sparse matrix would be beneficial to perform the text processing. The inbuilt sklearn packages use sparse matrix to perform computations. Let us use the sklearn packages to obtain the same TFIDF matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data represented as data frame:\n",
      "\n",
      "   Doc ID                                    Text\n",
      "0      d8               Backstreet Boys Musicians\n",
      "1      d9                           Cher Musician\n",
      "2      d6            The Rolling Stones Musicians\n",
      "3      d7           Tiger Woods Sportsperson Golf\n",
      "4      d4                         Tom Hanks Actor\n",
      "5      d5  Michael Jordan Sportsperson Basketball\n",
      "6      d2                  George Lucas Filmmaker\n",
      "7      d3    Oprah Winfrey Television personality\n",
      "8      d1                   Julia Roberts Actress\n",
      "9     d10              Steven Spielberg Filmmaker\n",
      "10    d11                        Tom Cruise Actor\n",
      "11    d12                      Bruce Willis Actor\n",
      "\n",
      "\n",
      "Run time using sklearn package is 0.0\n",
      "\n",
      "Some of the initial TFIDF rows:\n",
      "\n",
      "  (0, 2)\t0.604391549677\n",
      "  (0, 4)\t0.604391549677\n",
      "  (0, 17)\t0.519058483562\n",
      "  (1, 6)\t0.707106781187\n",
      "  (1, 16)\t0.707106781187\n",
      "  (2, 17)\t0.444226001257\n",
      "  (2, 27)\t0.517256628702\n",
      "  (2, 21)\t0.517256628702\n",
      "  (2, 25)\t0.517256628702\n",
      "  (3, 28)\t0.517256628702\n",
      "  (3, 32)\t0.517256628702\n",
      "  (3, 23)\t0.444226001257\n",
      "  (3, 10)\t0.517256628702\n",
      "  (4, 29)\t0.56467934145\n",
      "  (4, 11)\t0.657512463543\n",
      "  (4, 0)\t0.498813193115\n",
      "  (5, 23)\t0.444226001257\n",
      "  (5, 15)\t0.517256628702\n",
      "  (5, 12)\t0.517256628702\n",
      "  (5, 3)\t0.517256628702\n",
      "  (6, 9)\t0.604391549677\n",
      "  (6, 14)\t0.604391549677\n",
      "  (6, 8)\t0.519058483562\n",
      "  (7, 18)\t0.5\n",
      "  (7, 31)\t0.5\n",
      "  (7, 26)\t0.5\n",
      "  (7, 19)\t0.5\n",
      "  (8, 13)\t0.57735026919\n",
      "  (8, 20)\t0.57735026919\n",
      "  (8, 1)\t0.57735026919\n",
      "  (9, 8)\t0.519058483562\n",
      "  (9, 24)\t0.604391549677\n",
      "  (9, 22)\t0.604391549677\n",
      "  (10, 29)\t0.56467934145\n",
      "  (10, 0)\t0.498813193115\n",
      "  (10, 7)\t0.657512463543\n",
      "  (11, 0)\t0.472716373017\n",
      "  (11, 5)\t0.623112843184\n",
      "  (11, 30)\t0.623112843184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "df = pd.DataFrame(docs.items(),columns=[\"Doc ID\",\"Text\"])\n",
    "print \"Data represented as data frame:\\n\\n{}\".format(df)\n",
    "start=time()\n",
    "count_vect = CountVectorizer()\n",
    "df_counts = count_vect.fit_transform(df[\"Text\"])\n",
    "#print df_counts\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "df_tfidf = tfidf_transformer.fit_transform(df_counts)\n",
    "end=time()\n",
    "print \"\\n\\nRun time using sklearn package is {}\\n\".format(end-start)\n",
    "print \"Some of the initial TFIDF rows:\\n\\n{}\".format(df_tfidf[0:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you observe, the TFIDF values obtained by sklearn package is represented as a sparse matrix. Also the above results are not matching our implementation, since we did not normalize the TF and we used log10 in our function to compute IDF. The sklearn implementation of TFIDF uses a different IDF formula (see http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer for more information). But we should note that relatively the values represent same importance for all words in both the methods. Both have scored frequent words a low TFIDF value, while rare words a high TFIDF score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Implementing document retrieval system\n",
    "\n",
    "We will be using a data set called \"people_wiki.csv\" to implement a document retrieval system. This data set was as a part of Coursera Machine Learning course from University of Washington. The course used this data set to perfom text analytics using _graph lab create_ software. But we will implement our document retrieval system using sklearn packages. Other than the data set, I did _not_ use any code from the course in Coursera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some initial rows in the data set: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Digby_Morrell&gt;</td>\n",
       "      <td>Digby Morrell</td>\n",
       "      <td>digby morrell born 10 october 1979 is a former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Alfred_J._Lewy&gt;</td>\n",
       "      <td>Alfred J. Lewy</td>\n",
       "      <td>alfred j lewy aka sandy lewy graduated from un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Harpdog_Brown&gt;</td>\n",
       "      <td>Harpdog Brown</td>\n",
       "      <td>harpdog brown is a singer and harmonica player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Franz_Rottensteiner&gt;</td>\n",
       "      <td>Franz Rottensteiner</td>\n",
       "      <td>franz rottensteiner born in waidmannsfeld lowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/G-Enka&gt;</td>\n",
       "      <td>G-Enka</td>\n",
       "      <td>henry krvits born 30 december 1974 in tallinn ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URI                 name  \\\n",
       "0        <http://dbpedia.org/resource/Digby_Morrell>        Digby Morrell   \n",
       "1       <http://dbpedia.org/resource/Alfred_J._Lewy>       Alfred J. Lewy   \n",
       "2        <http://dbpedia.org/resource/Harpdog_Brown>        Harpdog Brown   \n",
       "3  <http://dbpedia.org/resource/Franz_Rottensteiner>  Franz Rottensteiner   \n",
       "4               <http://dbpedia.org/resource/G-Enka>               G-Enka   \n",
       "\n",
       "                                                text  \n",
       "0  digby morrell born 10 october 1979 is a former...  \n",
       "1  alfred j lewy aka sandy lewy graduated from un...  \n",
       "2  harpdog brown is a singer and harmonica player...  \n",
       "3  franz rottensteiner born in waidmannsfeld lowe...  \n",
       "4  henry krvits born 30 december 1974 in tallinn ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset summary: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59071</td>\n",
       "      <td>59071</td>\n",
       "      <td>59071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>59071</td>\n",
       "      <td>59070</td>\n",
       "      <td>59071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Andrew_Wildman&gt;</td>\n",
       "      <td>author)</td>\n",
       "      <td>beth denisch born augusta georgia feb 25 1958 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URI     name  \\\n",
       "count                                          59071    59071   \n",
       "unique                                         59071    59070   \n",
       "top     <http://dbpedia.org/resource/Andrew_Wildman>  author)   \n",
       "freq                                               1        2   \n",
       "\n",
       "                                                     text  \n",
       "count                                               59071  \n",
       "unique                                              59071  \n",
       "top     beth denisch born augusta georgia feb 25 1958 ...  \n",
       "freq                                                    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The data set has 59071 rows and 3 columns\n"
     ]
    }
   ],
   "source": [
    "##Reading the data set to a data frame\n",
    "X = pd.read_csv(\"people_wiki.csv\")\n",
    "\n",
    "print \"Some initial rows in the data set: \\n\"\n",
    "display(X.head())\n",
    "\n",
    "print \"\\nDataset summary: \\n\"\n",
    "display(X.describe())\n",
    "\n",
    "print \"\\nThe data set has {} rows and {} columns\".format(X.shape[0],X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set has 59071 rows and 3 columns. The URI column has the URL, the _name_ column has the person's name and the _text_ has the text related to the person in the _name_ column.\n",
    "\n",
    "### Project requirements\n",
    "The user interacts with this system by searching a list of word(s), and the system lists the topics matching the user search (the search must be fuzzy search. This means, if an exact word match is not found, the system should return the nearest matching topic). If the user is not satisfied with the results, he can search the database with new words. \n",
    "\n",
    "The user will select a topic from the listed topics. The system will display the topic's text, and recommends another set of topics, the user might be interested. \n",
    "\n",
    "### Approach\n",
    "\n",
    "1. We do not need the URI column in the data set, since the _text_ column has all the required data about the person.\n",
    "2. We will separate the _text_ column and _name_ columns into two data frames.\n",
    "3. We will get the TF-IDF for all the _text_ data using sklearn packages.\n",
    "4. We will use KNN (K Nearest Neigbbors) method of sklearn package, to get the relevant documents, based on the _current document_ or search words. \n",
    "\n",
    "\n",
    "### Implementation\n",
    "The python code to implement the above approach is listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X=pd.read_csv(\"people_wiki.csv\")\n",
    "#Get the name column to a different data frame\n",
    "y=X.pop(\"name\")\n",
    "\n",
    "#Drop the URI column\n",
    "X.drop([\"URI\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame X has all the text data, and the data frame y has all the people names. See the sample data of these two data frames below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X data frame's data \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>digby morrell born 10 october 1979 is a former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfred j lewy aka sandy lewy graduated from un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>harpdog brown is a singer and harmonica player...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>franz rottensteiner born in waidmannsfeld lowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>henry krvits born 30 december 1974 in tallinn ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  digby morrell born 10 october 1979 is a former...\n",
       "1  alfred j lewy aka sandy lewy graduated from un...\n",
       "2  harpdog brown is a singer and harmonica player...\n",
       "3  franz rottensteiner born in waidmannsfeld lowe...\n",
       "4  henry krvits born 30 december 1974 in tallinn ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y data frame's data \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          Digby Morrell\n",
       "1         Alfred J. Lewy\n",
       "2          Harpdog Brown\n",
       "3    Franz Rottensteiner\n",
       "4                 G-Enka\n",
       "Name: name, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print \"\\nX data frame's data \\n\"\n",
    "display(X.head())\n",
    "print \"\\ny data frame's data \\n\"\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing TF-IDF\n",
    "The following code computes the Term Frequency - Inverse Document Frequency (TFIDF) of all the _text_ data in X data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time using sklearn package is 26.3109998703 sec\n",
      "\n",
      "The TF-IDF matrix has 59071 rows and 548429 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "start=time()\n",
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(X[\"text\"])\n",
    "#print X_counts\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "end=time()\n",
    "print \"Run time using sklearn package is {} sec\\n\".format(end-start)\n",
    "#print \"Some of the initial TFIDF rows:\\n\\n{}\".format(X_tfidf[0:2])\n",
    "print \"The TF-IDF matrix has {} rows and {} columns\\n\".format(X_tfidf.shape[0],X_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation time along with the TF-IDF matrix's shape is displayed above. We can see that the TF-IDF matrix has 59071 rows and 548429 columns. This matrix is represented as a sparse matrix internally, and this representation will help for faster computations. Also the matrix has more columns than rows. Hence a dimensional reduction method like PCA (Principal Component Analysis) can help to reduce the dimensions. But we will not perform the PCA in this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a KNN model on TF-IDF data\n",
    "KNN (K Nearest Neighbor) model is fit on the TF-IDF data (present in X_tfidf data frame). This model will help us to retrieve the best 10 relevant documents, for a given document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=10, p=2, radius=1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=10,algorithm='brute' ,metric='cosine',leaf_size=30,p=2).fit(X_tfidf)\n",
    "nbrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User interface\n",
    "\n",
    "Let us create a simple user interface to accept a list of words and perform the document retrieval. This interface will help us to test our document retrieval system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of relevant topics retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Search a person\n",
      "2. Quit\n",
      "1\n",
      "\n",
      "\n",
      "Enter a search string in the below text box:\n",
      "obama\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barack Obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kenneth D. Thompson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jonathan Alter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samantha Power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John D. McCormick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Robert Gibbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Eric Holder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Joe the Plumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Steve Schale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Batton Lash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Topic\n",
       "0         Barack Obama\n",
       "1  Kenneth D. Thompson\n",
       "2       Jonathan Alter\n",
       "3       Samantha Power\n",
       "4    John D. McCormick\n",
       "5         Robert Gibbs\n",
       "6          Eric Holder\n",
       "7      Joe the Plumber\n",
       "8         Steve Schale\n",
       "9          Batton Lash"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a topic using the number listed beside the topic\n",
      "0\n",
      "barack hussein obama ii brk husen bm born august 4 1961 is the 44th and current president of the united states and the first african american to hold the office born in honolulu hawaii obama is a graduate of columbia university and harvard law school where he served as president of the harvard law review he was a community organizer in chicago before earning his law degree he worked as a civil rights attorney and taught constitutional law at the university of chicago law school from 1992 to 2004 he served three terms representing the 13th district in the illinois senate from 1997 to 2004 running unsuccessfully for the united states house of representatives in 2000in 2004 obama received national attention during his campaign to represent illinois in the united states senate with his victory in the march democratic party primary his keynote address at the democratic national convention in july and his election to the senate in november he began his presidential campaign in 2007 and after a close primary campaign against hillary rodham clinton in 2008 he won sufficient delegates in the democratic party primaries to receive the presidential nomination he then defeated republican nominee john mccain in the general election and was inaugurated as president on january 20 2009 nine months after his election obama was named the 2009 nobel peace prize laureateduring his first two years in office obama signed into law economic stimulus legislation in response to the great recession in the form of the american recovery and reinvestment act of 2009 and the tax relief unemployment insurance reauthorization and job creation act of 2010 other major domestic initiatives in his first term included the patient protection and affordable care act often referred to as obamacare the doddfrank wall street reform and consumer protection act and the dont ask dont tell repeal act of 2010 in foreign policy obama ended us military involvement in the iraq war increased us troop levels in afghanistan signed the new start arms control treaty with russia ordered us military involvement in libya and ordered the military operation that resulted in the death of osama bin laden in january 2011 the republicans regained control of the house of representatives as the democratic party lost a total of 63 seats and after a lengthy debate over federal spending and whether or not to raise the nations debt limit obama signed the budget control act of 2011 and the american taxpayer relief act of 2012obama was reelected president in november 2012 defeating republican nominee mitt romney and was sworn in for a second term on january 20 2013 during his second term obama has promoted domestic policies related to gun control in response to the sandy hook elementary school shooting and has called for full equality for lgbt americans while his administration has filed briefs which urged the supreme court to strike down the defense of marriage act of 1996 and californias proposition 8 as unconstitutional in foreign policy obama ordered us military involvement in iraq in response to gains made by the islamic state in iraq after the 2011 withdrawal from iraq continued the process of ending us combat operations in afghanistan and has sought to normalize us relations with cuba\n",
      "\n",
      "\n",
      "You may be interested in these people...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joe Biden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary Rodham Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samantha Power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eric Stern (politician)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>George W. Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>John McCain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Artur Davis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Henry Waxman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jeff Sessions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Topic\n",
       "1                Joe Biden\n",
       "2   Hillary Rodham Clinton\n",
       "3           Samantha Power\n",
       "4  Eric Stern (politician)\n",
       "5           George W. Bush\n",
       "6              John McCain\n",
       "7              Artur Davis\n",
       "8             Henry Waxman\n",
       "9            Jeff Sessions"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your choice. Enter Q to quit\n",
      "2\n",
      "hillary diane rodham clinton hlri dan rdm klntn born october 26 1947 is a former united states secretary of state us senator and first lady of the united states from 2009 to 2013 she was the 67th secretary of state serving under president barack obama she previously represented new york in the us senate 2001 to 2009 before that as the wife of the 42nd president of the united states bill clinton she was first lady from 1993 to 2001 in the 2008 election clinton was a leading candidate for the democratic presidential nominationa native of illinois hillary rodham was the first student commencement speaker at wellesley college in 1969 and earned a jd from yale law school in 1973 after a brief stint as a congressional legal counsel she moved to arkansas and married bill clinton in 1975 rodham cofounded arkansas advocates for children and families in 1977 in 1978 she became the first female chair of the legal services corporation and in 1979 the first female partner at rose law firm the national law journal twice listed her as one of the hundred most influential lawyers in america as first lady of arkansas from 1979 to 1981 and 1983 to 1992 with her husband as governor she led a task force that reformed arkansass education system during that time she was on the board of directors of walmart and several other corporationsin 1994 as first lady of the united states her major initiative the clinton health care plan failed to gain approval from the us congress however in 1997 and 1999 clinton played a leading role in advocating the creation of the state childrens health insurance program the adoption and safe families act and the foster care independence act her years as first lady drew a polarized response from the american public the only first lady to have been subpoenaed she testified before a federal grand jury in 1996 regarding the whitewater controversy but was never charged with wrongdoing in this or several other investigations during the clinton presidency her marriage endured the lewinsky scandal in 1998after moving to new york clinton was elected the first female senator from the state she is the only first lady ever to have run for public office following the september 11 2001 terrorist attacks she supported military action in afghanistan and the iraq war resolution but subsequently objected to the george w bush administrations conduct of the war in iraq she opposed most of bushs domestic policies clinton was reelected to the senate in 2006 running in the 2008 democratic presidential primaries clinton won far more primaries and delegates than any other female candidate in american history but narrowly lost the nomination to obamaselected to serve as secretary of state by obama clinton was confirmed by the senate in january 2009 she was at the forefront of the us response to the arab spring and advocated the us military intervention in libya as secretary of state she took responsibility for security lapses related to the 2012 benghazi attack which resulted in the deaths of american consulate personnel but defended her personal actions in regard to the matter clinton visited more countries than any other secretary of state she viewed smart power as the strategy for asserting us leadership and values by combining military power with diplomacy and american capabilities in economics technology and other areas she encouraged empowerment of women everywhere and used social media to communicate the us message abroad\n",
      "\n",
      "\n",
      "You may be interested in these people...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bill Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ann Lewis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barack Obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Melanne Verveer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jill Alper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vanessa Gilmore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sheila Widnall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>L. Jean Lewis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Samantha Power</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Topic\n",
       "1     Bill Clinton\n",
       "2        Ann Lewis\n",
       "3     Barack Obama\n",
       "4  Melanne Verveer\n",
       "5       Jill Alper\n",
       "6  Vanessa Gilmore\n",
       "7   Sheila Widnall\n",
       "8    L. Jean Lewis\n",
       "9   Samantha Power"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your choice. Enter Q to quit\n",
      "q\n"
     ]
    }
   ],
   "source": [
    "##### Function to search for a string (perform fuzzy search of string in X, and returns 10 matches\n",
    "##### 10 matches, since we trained the KNN algorithm with k=10\n",
    "def search_a_person(search_string,count_vect,tfidf_transformer,nbrs):\n",
    "    y_counts=count_vect.transform([search_string])\n",
    "    y_tfidf=tfidf_transformer.transform(y_counts)\n",
    "    i=nbrs.kneighbors(y_tfidf,return_distance=True)\n",
    "    display_df = pd.DataFrame(y.ix[i[1][0]]).reset_index(drop=True)\n",
    "    display_df.columns=[\"Topic\"]\n",
    "    return display_df\n",
    "\n",
    "###Function to retrieve the index to get the text associated with the index\n",
    "###Will search for an exact match in y (doc_ids parm), and returns a matching index in y (or doc_ids)\n",
    "def retrieve_topic(display_df,chosen_id,doc_ids):\n",
    "            i = doc_ids[doc_ids==display_df.iloc[int(chosen_id)][\"Topic\"]].index.tolist()\n",
    "            #return X[\"text\"][i[0]]\n",
    "            return i\n",
    "\n",
    "##Initialize the choice to 0        \n",
    "choice=0\n",
    "\n",
    "#Code to display the UI choices and to process the retrieval requests\n",
    "while int(choice) < 3:\n",
    "    #Display the initial menu\n",
    "    print \"1. Search a person\"\n",
    "    print \"2. Quit\"\n",
    "    \n",
    "    #Read the input from the interface\n",
    "    choice = raw_input()\n",
    "    \n",
    "    #validate the choice and take the action\n",
    "    try:\n",
    "        if int(choice) == 2:\n",
    "            break\n",
    "        if int(choice) == 1:\n",
    "            print \"\\n\\nEnter a search string in the below text box:\"\n",
    "            search_string=raw_input()\n",
    "            display_df=search_a_person(search_string,count_vect,tfidf_transformer,nbrs)\n",
    "            display(display_df)\n",
    "            \n",
    "            print \"Choose a topic using the number listed beside the topic\"\n",
    "            chosen_id = raw_input()\n",
    "            #try:\n",
    "            while int(chosen_id) < 10:\n",
    "                i=retrieve_topic(display_df,chosen_id,y)\n",
    "                print X[\"text\"][i[0]]\n",
    "                print \"\\n\\nYou may be interested in these people...\"\n",
    "                ip=X_tfidf[y[y==display_df.iloc[int(chosen_id)][\"Topic\"]].index.tolist()]\n",
    "                l = nbrs.kneighbors(ip,return_distance=True)\n",
    "                a=l[1].tolist()\n",
    "\n",
    "                #display_df=pd.DataFrame(zip(list(y.ix[a[0]]),l[0][0]),columns=[\"Topic\",\"Distance\"])\n",
    "                #display(display_df.iloc[1:])\n",
    "                display_df=pd.DataFrame(list(y.ix[a[0]]),columns=[\"Topic\"])\n",
    "                display(display_df.iloc[1:])\n",
    "\n",
    "                print \"Enter your choice. Enter Q to quit\"\n",
    "                chosen_id = raw_input()\n",
    "                if chosen_id == 'Q' or chosen_id == 'q':\n",
    "                    break\n",
    "                else:    \n",
    "                    continue\n",
    "                break  \n",
    "            #except:\n",
    "                #print \"Incorrect choice made. Quitting the program\"\n",
    "            break\n",
    "        else:\n",
    "            print \"\\nIncorrect choice. Enter 1 (for search) or 2 (for exit)\"\n",
    "            choice=0\n",
    "    except:\n",
    "        print \"\\nIncorrect choice. Enter 1 (for search) or 2 (for exit)\"\n",
    "        choice = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above set of program execution, we retrieved documents related to \"Obama\" first (we searched the documents for the word Obama, and the system has displayed the related documents. We chose the choice 0 for Barak Obama). The system has displayed the text related to Barak Obama, and also displayed some more topics (related to Barak Obama). The we chose the topic related to Hillary Clinton. This choice has displayed text related to Hillary Clintol, along with some related topics. We finally quit the system by entering \"q\".\n",
    "\n",
    "With two simple algorithms (TF-IDF and KNN), we are able to construct a decent document retrieval system. As a part of future work, we would like to work on the following:\n",
    "\n",
    "1. Use python's NLTK (Natural Language Tool Kit) to match the text, instead of TF-IDF algorithm, and compare the performances.\n",
    "2. Create a better GUI to perform testing.\n",
    "3. Perform the clustering of data using K Means clustering with/without transforming the data using PCA (Principal Component Analysis), and understand if PCA improves clustering of data.\n",
    "4. Fit a supervised learning algorithm to accurately predict the cluster to which a document belongs to.\n",
    "4. Improve the quality (and run-time) of suggested topics by searching the related topics within the relevant cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project we performed the following:\n",
    "1. Built a manual function to find the TF-IDF for a set of documents\n",
    "2. Found the run times of manual execution and in-built sklearn packages to calculate the TF-IDF values of a set of documents\n",
    "3. Built a document retrieval system on persons data set (from wikipedia), based on TF-IDF concept and KNN method. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
